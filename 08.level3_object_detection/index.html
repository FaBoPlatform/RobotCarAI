



<!DOCTYPE html>
<html lang="ja" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="クリップボードへコピー">
      
        <meta name="lang:clipboard.copied" content="コピーしました">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="何も見つかりませんでした">
      
        <meta name="lang:search.result.one" content="1件見つかりました">
      
        <meta name="lang:search.result.other" content="#件見つかりました">
      
        <meta name="lang:search.tokenizer" content="[\s\-　、。，．]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.1.0">
    
    
      
        <title>Index - FaBo RobotCarAI Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.11e41852.css">
      
      
    
    
      <script src="../assets/javascripts/modernizr.20ef595d.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.1/css/font-awesome.min.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#3" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="FaBo RobotCarAI Docs" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                FaBo RobotCarAI Docs
              </span>
              <span class="md-header-nav__topic">
                Index
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="FaBo RobotCarAI Docs" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    FaBo RobotCarAI Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="RobotCarAI" class="md-nav__link">
      RobotCarAI
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      00.install raspberry pi3
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        00.install raspberry pi3
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../00.install_raspberry_pi3/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      01.fabodrive
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        01.fabodrive
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../01.fabodrive/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      02.level1 car
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        02.level1 car
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../02.level1_car/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      03.level1 sensors
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        03.level1 sensors
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../03.level1_sensors/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      04.level1 demo
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        04.level1 demo
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../04.level1_demo/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      05.level2 lane detection
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        05.level2 lane detection
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../05.level2_lane_detection/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      06.level2 demo
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        06.level2 demo
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../06.level2_demo/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9">
    
    <label class="md-nav__link" for="nav-9">
      07.level2 demo socket
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        07.level2 demo socket
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../07.level2_demo_socket/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-10" type="checkbox" id="nav-10" checked>
    
    <label class="md-nav__link" for="nav-10">
      08.level3 object detection
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-10">
        08.level3 object detection
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Index
      </label>
    
    <a href="./" title="Index" class="md-nav__link md-nav__link--active">
      Index
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目次</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="カメラ映像を取得し、道路標識を検出する" class="md-nav__link">
    カメラ映像を取得し、道路標識を検出する
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="インストール方法" class="md-nav__link">
    インストール方法
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="コースの準備" class="md-nav__link">
    コースの準備
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raspberry-pi3" title="Raspberry Pi3での実行方法" class="md-nav__link">
    Raspberry Pi3での実行方法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-raspberry-pi3" title="1. ロボットカーのRaspberry Pi3にログインします" class="md-nav__link">
    1. ロボットカーのRaspberry Pi3にログインします
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-rootdockerid" title="2. rootになってdockerコンテナIDを調べます" class="md-nav__link">
    2. rootになってdockerコンテナIDを調べます
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-docker" title="3. dockerコンテナにログインします" class="md-nav__link">
    3. dockerコンテナにログインします
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" title="4. ロボットカーのディレクトリに移動します" class="md-nav__link">
    4. ロボットカーのディレクトリに移動します
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" title="5. スクリプト設定ファイルを編集します" class="md-nav__link">
    5. スクリプト設定ファイルを編集します
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-11" type="checkbox" id="nav-11">
    
    <label class="md-nav__link" for="nav-11">
      09.level3 demo socket
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-11">
        09.level3 demo socket
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../09.level3_demo_socket/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-12" type="checkbox" id="nav-12">
    
    <label class="md-nav__link" for="nav-12">
      10.level3 demo streaming
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-12">
        10.level3 demo streaming
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../10.level3_demo_streaming/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-13" type="checkbox" id="nav-13">
    
    <label class="md-nav__link" for="nav-13">
      11.level4 lane detection
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-13">
        11.level4 lane detection
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../11.level4_lane_detection/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-14" type="checkbox" id="nav-14">
    
    <label class="md-nav__link" for="nav-14">
      12.level5 demo streaming
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-14">
        12.level5 demo streaming
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../12.level5_demo_streaming/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目次</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="カメラ映像を取得し、道路標識を検出する" class="md-nav__link">
    カメラ映像を取得し、道路標識を検出する
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="インストール方法" class="md-nav__link">
    インストール方法
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="コースの準備" class="md-nav__link">
    コースの準備
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#raspberry-pi3" title="Raspberry Pi3での実行方法" class="md-nav__link">
    Raspberry Pi3での実行方法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-raspberry-pi3" title="1. ロボットカーのRaspberry Pi3にログインします" class="md-nav__link">
    1. ロボットカーのRaspberry Pi3にログインします
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-rootdockerid" title="2. rootになってdockerコンテナIDを調べます" class="md-nav__link">
    2. rootになってdockerコンテナIDを調べます
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-docker" title="3. dockerコンテナにログインします" class="md-nav__link">
    3. dockerコンテナにログインします
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" title="4. ロボットカーのディレクトリに移動します" class="md-nav__link">
    4. ロボットカーのディレクトリに移動します
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" title="5. スクリプト設定ファイルを編集します" class="md-nav__link">
    5. スクリプト設定ファイルを編集します
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <p><a name='top'></p>
<p>【タイトル】</p>
<h1 id="3">レベル3：ニューラルネットワークで道路標識を検出する</h1>
<hr>

<p>【目標】</p>
<h4 id="_1">カメラ映像を取得し、道路標識を検出する</h4>
<p>【画像】<br>
<img alt="" src="document/jetson_tx2-stop.png" /><br>
<img alt="" src="document/course.jpg" /><br></p>
<p>【動画】<br>
止まれを検出する動画：<a href="document/stop.mp4">./document/stop.mp4</a><br>
走行しながら道路標識を検出する動画：<a href="document/course160x120.mp4">./document/course160x120.mp4</a><br></p>
<p>【実行環境】<br>
<em> Fabo TYPE1 ロボットカー<br>
  * USB Webcam<br>
  * Raspberry Pi3<br>
    * Jessie Lite<br>
    * docker<br>
      * Ubuntu<br>
      * Python 2.7<br>
      * OpenCV 2.4<br>
      * Tensorflow r1.1.0<br>
</em> Jetson TX2<br>
  * USB Webcam<br>
  * JetPack 3.1<br>
    * Ubuntu<br>
    * Python 3.6<br>
    * OpenCV 3.3<br>
    * Tensorflow r1.4.1<br></p>
<hr>

<p><a name='0'></p>
<p>【実行】<br>
<em> <a href="#a">インストール方法</a><br>
</em> <a href="#course">コースの準備</a><br>
<em> <a href="#b">Raspberry Pi3での実行方法</a><br>
</em> <a href="#c">Jetson TX2での実行方法</a><br></p>
<p>【目次】<br>
<em> <a href="#1">物体検出の紹介</a><br>
  * object detection<br>
    * [OpenCV] [テンプレートマッチング]<br>
    * [Python] [Selective Search]<br>
    * [Neural Networks] [SSD: Single Shot MultiBox Detection]<br>
    * [Python/TensorFlow] [TensorFlow Object Detection API]<br>
</em> [Python/OpenCV/TensorFlow] <a href="#2">Balancap SSD-Tensorflowを使う</a><br>
  * インストール<br>
  * demo実行<br>
  * 扱える学習データフォーマット<br>
  * 学習データを作成する<br>
  * 学習コードの作成と学習実行<br>
  * 検出実行<br>
  * カメラ映像の読み込み<br>
  * ストリーミング配信<br>
  * ストリーミング解析実行<br>
  * 動画に保存<br>
<em> <a href="#3">ディレクトリとファイルについて</a><br>
</em> <a href="#4">開発/学習/実行環境について</a><br>
<hr></p>
<p><a name='a'></p>
<h2 id="_2">インストール方法</h2>
<p>インストール済みのロボットカー/Jetson TX2を用意しているので省略します。<br></p>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a>
<hr></p>
<p><a name='course'></p>
<h2 id="_3">コースの準備</h2>
<p>ここは画像を元に解析をおこなう項目なので、ロボットカーは走行しないのでコースの準備は不要です。<br></p>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a>
<hr></p>
<h2 id="raspberry-pi3">Raspberry Pi3での実行方法</h2>
<h4 id="1-raspberry-pi3">1. ロボットカーのRaspberry Pi3にログインします</h4>
<p>USER:pi<br>
PASSWORD:raspberry<br></p>
<blockquote>
<p><code>ssh pi@192.168.xxx.xxx</code><br></p>
</blockquote>
<h4 id="2-rootdockerid">2. rootになってdockerコンテナIDを調べます</h4>
<blockquote>
<p><code>sudo su</code><br>
<code>docker ps -a</code><br></p>
<blockquote>
<p>CONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS                     PORTS                                                                    NAMES<br>
2133fa3ca362        naisy/fabo-jupyter-armhf   "/bin/bash -c 'jup..."   3 weeks ago         Up 2 minutes               0.0.0.0:6006-&gt;6006/tcp, 0.0.0.0:8091-&gt;8091/tcp, 0.0.0.0:8888-&gt;8888/tcp   hardcore_torvalds<br></p>
</blockquote>
</blockquote>
<p>STATUSがUpになっているコンテナIDをメモします。</p>
<h4 id="3-docker">3. dockerコンテナにログインします</h4>
<p>docker exec -it CONTAINER_ID /bin/bash<br></p>
<blockquote>
<p><code>docker exec -it 2133fa3ca362 /bin/bash</code><br></p>
</blockquote>
<p>CONTAINER_IDにはベースイメージがnaisy/fabo-jupyter-armhfの2133fa3ca362を使います。<br></p>
<h4 id="4">4. ロボットカーのディレクトリに移動します</h4>
<blockquote>
<p><code>cd /notebooks/github/RobotCarAI/level3_object_detection/</code><br>
<code>ls</code><br></p>
<blockquote>
<p>total 92<br>
1467711  4 ./                        1468006 32 README.md<br>
1446753  4 ../                       1468007  4 roadsign_data/<br>
1467903  4 demo_images/              1446969  8 run_ssd.py<br>
1467990  4 install_scripts/          1446978 12 run_streaming.py<br>
1467997  4 lib/                      1469662  4 script_define.conf<br>
1468000  4 model/                    1474562  4 train_scripts/<br>
1468003  4 patch_to_SSD-Tensorflow/<br></p>
</blockquote>
</blockquote>
<h4 id="5">5. スクリプト設定ファイルを編集します</h4>
<p>dockerのディレクトリパスに合わせて編集します。<br></p>
<blockquote>
<p><code>vi script_define.conf</code><br></p>
<blockquote>
<h1 id="_4">編集前<br></h1>
<p>GIT_DIR=/home/ubuntu/notebooks/github<br>
... <br>
VOC_DATASET_DIR=/home/ubuntu/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/PascalVOC<br>
TF_DATASET_DIR=/home/ubuntu/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/tfrecords<br></p>
<h1 id="_5">編集後<br></h1>
<p>GIT_DIR=/notebooks/github<br>
... <br>
VOC_DATASET_DIR=/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/PascalVOC<br>
TF_DATASET_DIR=/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/tfrecords<br></p>
</blockquote>
</blockquote>
<h4 id="6">6. インストールスクリプトに実行権限を付与して実行します</h4>
<blockquote>
<p><code>chmod 755 ./install_scripts/*.sh</code><br>
<code>./install_scripts/install.sh</code><br></p>
</blockquote>
<p>すでに実行してある場合は、再実行すると以下のようになりますので、パッチを戻すか？という問いにはnで答えてください。<br></p>
<blockquote>
<p>fatal: destination path 'SSD-Tensorflow' already exists and is not an empty directory.<br>
Archive:  ssd_300_vgg.ckpt.zip<br>
 inflating: ssd_300_vgg.ckpt.index  <br>
patching file /notebooks/github/SSD-Tensorflow/preprocessing/ssd_vgg_preprocessing.py<br>
Reversed (or previously applied) patch detected!  Assume -R? [n] n<br>
Apply anyway? [n] n<br>
Skipping patch.<br>
1 out of 1 hunk ignored -- saving rejects to file /notebooks/github/SSD-Tensorflow/preprocessing/ssd_vgg_preprocessing.py.rej<br>
patching file /notebooks/github/SSD-Tensorflow/nets/ssd_vgg_300.py<br>
Reversed (or previously applied) patch detected!  Assume -R? [n] n<br>
Apply anyway? [n] n<br>
Skipping patch.<br>
3 out of 3 hunks ignored -- saving rejects to file /notebooks/github/SSD-Tensorflow/nets/ssd_vgg_300.py.rej<br></p>
</blockquote>
<p>よくわからなくなったら、SSD-Tensorflowのディレクトリを削除してからインストールスクリプトを実行してください。<br></p>
<blockquote>
<p><code>rm -rf /notebooks/github/SSD-Tensorflow/</code><br>
<code>./install_scripts/install.sh</code><br></p>
</blockquote>
<h4 id="6_1">6. トレーニングスクリプトに実行権限を付与して実行します</h4>
<blockquote>
<p><code>chmod 755 ./train_scripts/*.sh</code><br>
<code>./train_scripts/setup_mytrain.sh</code><br></p>
<blockquote>
<p>total objects:891<br>
label:objects:images<br>
stop:149:142<br>
speed_10:202:185<br>
speed_20:356:349<br>
speed_30:184:184<br></p>
</blockquote>
</blockquote>
<p>実際の学習は多くのGPUメモリを搭載したマシンが必要となるので、ここでは学習は行いません。<br></p>
<h4 id="7">7. 道路標識の検出を実行します</h4>
<blockquote>
<p><code>python run_ssd.py</code><br></p>
<blockquote>
<p>time:116.36789203 clock:54.87105800<br>
time:15.70358896 clock:51.92819900<br>
time:14.47124100 clock:51.34533300<br>
time:14.39473701 clock:50.40863100<br>
time:17.08592391 clock:51.68568700<br>
time:14.97833300 clock:47.98345900<br>
time:12.63103414 clock:47.83602600<br>
time:12.64851999 clock:48.24852800<br>
time:12.63877583 clock:47.83689600<br>
time:12.62398911 clock:48.13235200<br>
time:12.84498405 clock:48.04971600<br>
time:12.57889819 clock:47.78148500<br>
time:12.74054813 clock:48.23995300<br>
end<br></p>
</blockquote>
</blockquote>
<p>Raspberry Pi3は物体検出を行うには非常に非力なので、実行には少し時間がかかります。<br></p>
<h4 id="8">8. 検出結果を確認します</h4>
<p>ブラウザでRaspberry Pi3のjupyterにアクセスします<br></p>
<blockquote>
<p>http://192.168.xxx.xxx:8888/tree/github/RobotCarAI/level3_object_detection/output/<br></p>
</blockquote>
<p>jupyterのpasswordは別途説明があるかと思います。<br></p>
<p>result_*.jpg が検出結果の画像になります。<br></p>
<p>入力に使ったデータは、result_の付いていない画像になります。<br></p>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a>
<hr></p>
<h2 id="jetson-tx2">Jetson TX2での実行方法</h2>
<h4 id="1-jetson-tx2">1. Jetson TX2にログインします</h4>
<p>USER:ubuntu<br>
PASSWORD:ubuntu<br></p>
<blockquote>
<p><code>ssh ubuntu@192.168.xxx.xxx</code><br></p>
</blockquote>
<p>用意してあるJetson TX2はDockerを使っていないので、Raspberry Pi3の時のようなdockerコンテナへのログインはありません。<br></p>
<h4 id="2">2. ロボットカーのディレクトリに移動します</h4>
<blockquote>
<p><code>cd ~/notebooks/github/RobotCarAI/level3_object_detection/</code><br>
<code>ls</code><br></p>
<blockquote>
<p>total 92<br>
1467711  4 ./                        1468006 32 README.md<br>
1446753  4 ../                       1468007  4 roadsign_data/<br>
1467903  4 demo_images/              1446969  8 run_ssd.py<br>
1467990  4 install_scripts/          1446978 12 run_streaming.py<br>
1467997  4 lib/                      1469662  4 script_define.conf<br>
1468000  4 model/                    1474562  4 train_scripts/<br>
1468003  4 patch_to_SSD-Tensorflow/<br></p>
</blockquote>
</blockquote>
<h4 id="3_1">3. インストールスクリプトに実行権限を付与して実行します</h4>
<p>スクリプト設定ファイルはJetson TX2の環境に合わせて用意してあるので編集の必要はないので、インストールスクリプトの実行を行ってください。<br></p>
<blockquote>
<p><code>chmod 755 ./install_scripts/*.sh</code><br>
<code>./install_scripts/install.sh</code><br></p>
</blockquote>
<p>すでに実行してある場合は、再実行すると以下のようになりますので、パッチを戻すか？という問いにはnで答えてください。<br></p>
<blockquote>
<p>fatal: destination path 'SSD-Tensorflow' already exists and is not an empty directory.<br>
Archive:  ssd_300_vgg.ckpt.zip<br>
patching file /home/ubuntu/notebooks/github/SSD-Tensorflow/preprocessing/ssd_vgg_preprocessing.py<br>
Reversed (or previously applied) patch detected!  Assume -R? [n] n<br>
Apply anyway? [n] n<br>
Skipping patch.<br>
1 out of 1 hunk ignored -- saving rejects to file /home/ubuntu/notebooks/github/SSD-Tensorflow/preprocessing/ssd_vgg_preprocessing.py.rej<br>
patching file /home/ubuntu/notebooks/github/SSD-Tensorflow/nets/ssd_vgg_300.py<br>
Reversed (or previously applied) patch detected!  Assume -R? [n] n<br>
Apply anyway? [n] n<br>
Skipping patch.<br>
3 out of 3 hunks ignored -- saving rejects to file /home/ubuntu/notebooks/github/SSD-Tensorflow/nets/ssd_vgg_300.py.rej<br></p>
</blockquote>
<p>よくわからなくなったら、SSD-Tensorflowのディレクトリを削除してからインストールスクリプトを実行してください。<br></p>
<blockquote>
<p><code>rm -rf /home/ubuntu/notebooks/github/SSD-Tensorflow/</code><br>
<code>./install_scripts/install.sh</code><br></p>
</blockquote>
<h4 id="4_1">4. トレーニングスクリプトに実行権限を付与して実行します</h4>
<blockquote>
<p><code>chmod 755 ./train_scripts/*.sh</code><br>
<code>./train_scripts/setup_mytrain.sh</code><br></p>
<blockquote>
<p>total objects:891<br>
label:objects:images<br>
stop:149:142<br>
speed_10:202:185<br>
speed_20:356:349<br>
speed_30:184:184<br></p>
</blockquote>
</blockquote>
<p>実際の学習は多くのGPUメモリを搭載したマシンが必要となるので、ここでは学習は行いません。<br>
Jetson TX2は8GBのGPUメモリがありますが、これでも学習には向きません。<br>
この学習は、AWS p3.2xlargeインスタンスで1日程度実行してあります。<br></p>
<h4 id="5_1">5. 道路標識の検出を実行します</h4>
<blockquote>
<p><code>python run_ssd.py</code><br></p>
<blockquote>
<p>time:25.23302293 clock:23.77420100<br>
time:1.77238727 clock:1.49304700<br>
time:1.77872753 clock:1.42159600<br>
time:1.78329659 clock:1.58512700<br>
time:1.76960158 clock:1.57257700<br>
time:1.41074395 clock:1.13222900<br>
time:0.36464643 clock:0.34475100<br>
time:0.36422086 clock:0.34886500<br>
time:0.36535668 clock:0.35530400<br>
time:0.35956836 clock:0.34501500<br>
time:0.36577463 clock:0.35173300<br>
time:0.37001014 clock:0.35788600<br>
time:0.36742902 clock:0.35056400<br>
end<br></p>
</blockquote>
</blockquote>
<p>Jetson TX2はRaspberry Pi3よりかなり実行速度が速いことが分かります。<br></p>
<h4 id="8_1">8. 検出結果を確認します</h4>
<p>ブラウザでJetson TX2のjupyterにアクセスします<br></p>
<blockquote>
<p>http://192.168.xxx.xxx:8888/tree/github/RobotCarAI/level3_object_detection/output/<br></p>
</blockquote>
<p>jupyterのpasswordは別途説明があるかと思います。<br></p>
<p>result_*.jpg が検出結果の画像になります。<br></p>
<p>入力に使ったデータは、result_の付いていない画像になります。<br></p>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a>
<hr></p>
<p><a name='1'></p>
<h2 id="_6">物体検出の紹介</h2>
<p>画像ベースで識別する方法は大きくわけて3種類あります。<br>
<img alt="" src="document/detection.png" /><br>
Classificationは画像1枚で判断します。<br>
Object Detectionは画像の特定の領域で判断します。<br>
Segmentationは画像の1画素単位で判断します。<br>
Semantic Segmentationは1ピクセル毎のクラス分類ですが、Mask R-CNNではInstance Segmentationと呼ばれる物体のパーツ毎の識別になります。<br>
Classificationの方が処理速度が速く、Segmentationになると処理速度が遅くなります。<br></p>
<p>今回はSSD300を使ったObject Detectionで道路標識を検出します。<br>
SSDのデメリットとして、小さい物体は検出出来ない問題があります。SSDではアスペクト比を変更して学習するため、ボックスが潰れてしまうために発生します。<br></p>
<h4 id="opencv">[OpenCV] テンプレートマッチング</h4>
<p>昔からある方法としては、黒枠などのテンプレート画像を検索する方法があり、OpenCVで使う事が出来ます。<br>
検出には入力画像内にあるテンプレート同様の画像サイズが、用意したテンプレート画像サイズとほぼ一致している必要があるため、複数のサイズでテンプレートを用意します。<br>
黒枠を検出したら、その内部をCNNで画像識別して結果を得ます。
<hr></p>
<h4 id="python-selective-search">[Python] Selective Search</h4>
<p>候補領域を選出し、その内部をCNNで画像識別して結果を得ます。<br>
テンプレートの用意は不要ですが、候補領域はアルゴリズムで算出されるため、領域が出なければ識別にかけることは出来ません。<br>
1つの画像に候補領域が大量に出てくると識別回数が増えて遅くなります。<br>
<hr></p>
<h4 id="neural-networks-ssd-single-shot-multibox-detection">[Neural Networks] SSD: Single Shot MultiBox Detection</h4>
<p>VGG16を内部に持ち、DeepLearningによる物体検出と識別を行います。<br>
TensorFlowでのコードが公開されていますので、今回はこれを使うことにします。<br></p>
<hr>

<h4 id="pythontensorflow-tensorflow-object-detection-api">[Python/TensorFlow] TensorFlow Object Detection API</h4>
<p>TensorFlow公式で用意されている物体検出APIです。<br>
様々なモデルを使うことが出来ますが、バージョンアップに伴うトラブルもあるため、今後に期待します。<br></p>
<p>おすすめの物体検出として、TensorFlow Object Detection APIの実行効率を大幅に改修したssd_movilenet_v1があります。<br>
オリジナル：<a href="https://github.com/GustavZ/realtime_object_detection">realtime_object_detection</a><br>
道路標識版：<a href="https://github.com/naisy/realtime_object_detection">realtime_object_detection</a><br>
ssd_mobilenet_v1の学習方法：<a href="https://github.com/naisy/train_ssd_mobilenet">train_ssd_mobilenet</a><br></p>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a>
<hr></p>
<p><a name='2'></p>
<h2 id="pythonopencvtensorflow-balancap-ssd-tensorflow">[Python/OpenCV/TensorFlow] Balancap SSD-Tensorflowを使う</h2>
<p>TensorFlowを使った物体検出として、Balancap SSD-Tensorflowを使って道路標識を学習し、Jetson TX2で実行してみます。
Balancap SSD-Tensorflow：<a href="https://github.com/balancap/SSD-Tensorflow">https://github.com/balancap/SSD-Tensorflow</a></p>
<h4 id="_7">インストール</h4>
<p>インストール先や学習コード生成に必要な情報はスクリプト設定ファイルで用意しました。環境に合わせて修正してください。<br>
デフォルトでは/home/ubuntu/notebooks/github/...としてあります。<br></p>
<p>スクリプト設定ファイル：<a href="script_define.conf">./script_define.conf</a><br></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class=code><div class=codehilite><pre><span></span><span class=c1># Balancap SSD-Tensorflowのディレクトリ</span>
<span class=nv>GIT_DIR</span><span class=o>=</span>/home/ubuntu/notebooks/github
<span class=nv>SSD_TENSORFLOW_DIR</span><span class=o>=</span><span class=nv>$GIT_DIR</span>/SSD-Tensorflow

<span class=c1># データ名</span>
<span class=nv>MY_TRAIN</span><span class=o>=</span>roadsign
<span class=c1># 学習データディレクトリ</span>
<span class=nv>VOC_DATASET_DIR</span><span class=o>=</span>/home/ubuntu/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/PascalVOC
<span class=nv>TF_DATASET_DIR</span><span class=o>=</span>/home/ubuntu/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/tfrecords

<span class=c1># 道路標識の学習データで使うラベル</span>
<span class=c1># LABELS[0]はbackground(その他)用に空けておく</span>
<span class=c1># 学習データのラベルを増やす時はここにも追加する</span>
LABELS<span class=o>[</span><span class=m>1</span><span class=o>]=</span>stop
LABELS<span class=o>[</span><span class=m>2</span><span class=o>]=</span>speed_10
LABELS<span class=o>[</span><span class=m>3</span><span class=o>]=</span>speed_20
LABELS<span class=o>[</span><span class=m>4</span><span class=o>]=</span>speed_30

<span class=c1># 新規VGG16 checkpoint</span>
<span class=nv>CHECKPOINT_PATH</span><span class=o>=</span><span class=nv>$SSD_TENSORFLOW_DIR</span>/checkpoints/vgg_16.ckpt
<span class=c1># 学習を再開するcheckpoint</span>
<span class=nv>LEARNED_CHECKPOINT_PATH</span><span class=o>=</span><span class=nv>$GIT_DIR</span>/RobotCarAI/level3_object_detection/output/model.ckpt-7352
</pre></div></td></tr></table></p>
<hr>

<p>Balancap SSD-Tensorflow インストールスクリプト：<a href="install_scripts/install.sh">./install_scripts/install.sh</a><br></p>
<blockquote>
<p><code>chmod 755 ./install_scripts/*.sh</code><br>
<code>./install_scripts/install.sh</code><br></p>
</blockquote>
<hr>

<h4 id="demo">demo実行</h4>
<p>jupyterでSSD-Tensorflow/notebooks/ssd_notebook.ipynb を開いて実行します。
<hr></p>
<h4 id="_8">扱える学習データフォーマット</h4>
<p>SSD-Tensorflowで扱うことの出来るデータフォーマットはPascalVOC形式になります。<br>
自前の学習データを用意する際は、PascalVOC形式で作成する必要があります。
<hr></p>
<h4 id="_9">学習データを作成する</h4>
<p>学習データはGUIツールのLabelImgを使って作成します。<br>
LabelImg：<a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a><br>
LabelImg インストールスクリプト：<a href="install_scripts/install_labelimg.sh">./install_scripts/install_labelimg.sh</a><br></p>
<blockquote>
<p><code>./install_scripts/install_labelimg.sh</code><br></p>
</blockquote>
<p><img alt="labelImg.png" src="document/labelImg.png" /></p>
<p>GUIツールなので画面のある開発環境で学習データを作成してください。<br>
labelImgで作成したラベルは画像ファイルと同じディレクトリに作成されます。<br>
Balancap SSD-Tensorflowでは、TF-Recordへのコンバート時は画像ファイルをJPEGImagesに、ラベルファイルをAnnotationsに分けておく必要があります。<br></p>
<p>画像データ:<a href="./roadsign_data/PascalVOC/JPEGImages">./roadsign_data/PascalVOC/JPEGImages/</a><br>
ラベルデータ:<a href="./roadsign_data/PascalVOC/Annotations/">./roadsign_data/PascalVOC/Annotations/</a><br></p>
<p>学習データを作ったら、学習用コードの作成、データの変換、学習、となります。<br>
<hr></p>
<h4 id="_10">学習コードの作成と実行</h4>
<p>Balancap SSD-Tensorflowの学習コードは、元の学習コードをコピーしてスクリプトで修正して作成します。<br>
<hr></p>
<p>スクリプト設定ファイルで以下を設定します。
<em> 学習データディレクトリ
</em> ラベル</p>
<p>スクリプト設定ファイル：<a href="script_define.conf">./script_define.conf</a><br></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class=code><div class=codehilite><pre><span></span><span class=c1># 学習データディレクトリ</span>
<span class=nv>VOC_DATASET_DIR</span><span class=o>=</span>/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/PascalVOC
<span class=nv>TF_DATASET_DIR</span><span class=o>=</span>/notebooks/github/RobotCarAI/level3_object_detection/roadsign_data/tfrecords

<span class=c1># 道路標識の学習データで使うラベル</span>
<span class=c1># LABELS[0]はbackground(その他)用に空けておく</span>
<span class=c1># 学習データのラベルを増やす時はここにも追加する</span>
LABELS<span class=o>[</span><span class=m>1</span><span class=o>]=</span>stop
LABELS<span class=o>[</span><span class=m>2</span><span class=o>]=</span>speed_10
LABELS<span class=o>[</span><span class=m>3</span><span class=o>]=</span>speed_20
LABELS<span class=o>[</span><span class=m>4</span><span class=o>]=</span>speed_30
</pre></div></td></tr></table></p>
<hr>

<p>スクリプトコードを作成し、PascalVOCデータをTF-Recordsに変換して学習を実行します。<br>
スクリプト作成コード：<a href="train_scripts/setup_mytrain.sh">./train_scripts/setup_mytrain.sh</a><br>
データ変換コード：<a href="train_scripts/convert_PascalVOC_to_TF-Records.sh">./train_scripts/convert_PascalVOC_to_TF-Records.sh</a><br>
学習実行コード：<a href="train_scripts/train_ssd.sh">./train_scripts/train_ssd.sh</a><br></p>
<blockquote>
<p><code>chmod 755 ./train_scripts/*</code><br>
<code>./train_scripts/setup_mytrain.sh</code><br>
<code>./train_scripts/convert_PascalVOC_to_TF-Records.sh</code><br>
<code>./train_scripts/train_ssd.sh</code><br>
<code>./train_scripts/freeze_graph.sh</code><br></p>
</blockquote>
<p>学習はGPUを搭載した学習環境でおこないます。<br>
一定時間毎にcheckpointが保存されるので、適当なところでCtrl_z; kill %%で学習を停止してください。<br></p>
<p>途中のチェックポイントから学習を再開する際は、スクリプト設定ファイルのLEARNED_CHECKPOINT_PATHに再開するチェックポイントを指定して学習を再開します。<br>
スクリプト設定ファイル：<a href="script_define.conf">./script_define.conf</a><br></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre>1
2</pre></div></td><td class=code><div class=codehilite><pre><span></span><span class=c1># 学習済みcheckpoint</span>
<span class=nv>LEARNED_CHECKPOINT_PATH</span><span class=o>=</span><span class=nv>$GIT_DIR</span>/RobotCarAI/level3_object_detection/output/model.ckpt-7352
</pre></div></td></tr></table></p>
<p>学習再開クリプト：<a href="train_scripts/train_ssd_continue.sh">./train_scripts/train_ssd_continue.sh</a><br></p>
<blockquote>
<p><code>./train_scripts/train_ssd_continue.sh</code><br></p>
</blockquote>
<hr>

<p>Balancap SSD-Tensorflowではjpegしか扱えないため、pngで画像を用意した場合は変換が必要になります。  </p>
<blockquote>
<p><code>apt-get install imagemagick</code><br>
<code># png to jpg</code><br>
<code>for i in *.png ; do convert "$i" "${i%.*}.jpg" ; done</code><br>
<code># replace xml</code><br>
<code>find ./ -name "*.xml" | xargs sed -i 's/\.png/.jpg/g'</code><br></p>
</blockquote>
<hr>

<h4 id="_11">検出実行</h4>
<p>pbファイルを読み込んで実行します。<br></p>
<p>検出結果は層毎に出てくるため、SSDNetクラスを使って集計を行います。<br>
検出実行コード：<a href="run_ssd.py">./run_ssd.py</a><br></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre>1
2</pre></div></td><td class=code><div class=codehilite><pre><span></span>        <span class=c1># 予測実行</span>
        <span class=n>rclasses</span><span class=p>,</span> <span class=n>rscores</span><span class=p>,</span> <span class=n>rbboxes</span> <span class=o>=</span>  <span class=n>process_image</span><span class=p>(</span><span class=n>sess</span><span class=p>,</span><span class=n>cv_bgr</span><span class=p>)</span>
</pre></div></td></tr></table></p>
<p>検出実行コード：<a href="run_ssd.py">./run_ssd.py</a></p>
<blockquote>
<p><code>python run_ssd.py</code><br></p>
</blockquote>
<p>Jetson TX2<br></p>
<blockquote>
<p>time:19.86998034 clock:18.56985800
time:1.03599119 clock:0.93754800
time:1.04325247 clock:0.87934800
time:1.03981328 clock:0.94516900
time:1.04054499 clock:0.94298500
time:0.78034067 clock:0.67906600
time:0.78434491 clock:0.73667700
time:0.78234601 clock:0.72538500
time:0.78174305 clock:0.72879300
time:0.78478503 clock:0.73397900
time:0.78188086 clock:0.72555700
time:0.78177857 clock:0.73014300
time:0.78230286 clock:0.72738200
end</p>
</blockquote>
<p>Raspberry Pi3<br></p>
<blockquote>
<p>time:120.14480400 clock:55.83521200
time:16.20854115 clock:52.09492600
time:14.21805596 clock:51.28959800
time:15.57702303 clock:51.27450300
time:15.50608397 clock:51.43209300
time:13.86155987 clock:47.86049200
time:12.60688901 clock:47.83934000
time:12.60392714 clock:48.27811200
time:12.68156099 clock:47.87609600
time:12.59844589 clock:48.02762300
time:12.67574501 clock:48.29297900
time:12.60959601 clock:47.78995400
time:12.69101310 clock:48.27239100
end</p>
</blockquote>
<p>最初の1回目はJITになっているのか遅いです。<br>
2回目以降はJetson TX2とRaspberry Pi3では物体検出の実行速度に15倍以上の差があります。<br></p>
<p>/notebooks/github/RobotCarAI/level3_object_detection/output/以下に検出元画像と検出結果画像があります。</p>
<hr>

<h4 id="_12">カメラ映像の読み込み</h4>
<p>画像の時と同じで、カメラ映像の時も1フレームを1画像として読み込みます。<br></p>
<p>画像の読み込み<br>
検出実行コード：<a href="run_ssd.py">./run_ssd.py</a><br></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre>1</pre></div></td><td class=code><div class=codehilite><pre><span></span>        <span class=n>cv_bgr</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=n>DEMO_DIR</span><span class=o>+</span><span class=s2>&quot;/&quot;</span> <span class=o>+</span> <span class=n>file_name</span><span class=p>)</span>
</pre></div></td></tr></table></p>
<p>カメラ映像の読み込み<br>
WebCamストリーミング解析コード：<a href="run_streaming.py">./run_streaming.py</a></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre>1
2
3</pre></div></td><td class=code><div class=codehilite><pre><span></span>    <span class=n>vid</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=c1># WebCam Jetson TX2 /dev/video1</span>
<span class=o>...</span>
            <span class=n>retval</span><span class=p>,</span> <span class=n>cv_bgr</span> <span class=o>=</span> <span class=n>vid</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</pre></div></td></tr></table></p>
<p>Jetson TX2の場合は/dev/video1がUSBカメラデバイスなので、cv2.VideoCapture(1)となります。<br>
Raspberry Pi3やPCでは/dev/video0がUSBカメラデバイスなので、cv2.VideoCapture(0)となります。<br></p>
<p>UDPストリーミングで動画が送られている場合は、vid = cv2.VideoCapture('udp://localhost:8090')のようにUDPポートを指定して受信します。<br>
USBカメラが未接続だったり、ストリーミングが開始されていない時は映像取得に失敗します。
<hr></p>
<h4 id="_13">ストリーミング配信</h4>
<h5 id="ffmpeg-udp-streaming">FFMPEG UDP Streamingを使う場合</h5>
<p>送信側コマンド(192.168.0.77は受信側アドレス)<br></p>
<blockquote>
<p><code>ffmpeg -thread_queue_size 1024 -r 30 -video_size 160x120 -input_format yuyv422 -i /dev/video0 -pix_fmt yuv422p -threads 4 -f mpegts udp://192.168.0.77:8090</code><br></p>
</blockquote>
<p>受信側確認コマンド(動画プレイヤーが立ち上がるので、画面のあるPCで確認する場合になります)</p>
<blockquote>
<p><code>ffplay udp://localhost:8090</code><br></p>
</blockquote>
<p>ロボットカーのRaspberry Pi3では、<a href="../level3_demo_streaming#c">level3_demo_streaming</a>でFFMPEG用にdockerイメージを用意してありますので、それを使うことができます。<br>
サーバに合わせてIPアドレスを変更してください。<br></p>
<blockquote>
<p><code>sudo su</code><br></p>
</blockquote>
<p>dockerコンテナを作成する<br></p>
<blockquote>
<p><code>docker run -itd --device=/dev/video0:/dev/video0 ffmpeg /bin/bash -c "ffmpeg -thread_queue_size 1024 -r 1 -video_size 160x120 -input_format yuyv422 -i /dev/video0 -pix_fmt yuv422p -threads 4 -f mpegts udp://192.168.0.77:8090"</code><br></p>
<blockquote>
<p>95cbdd5f98b6981259e6b29a7e11ea3c24c945e7157ec4725a2d8d8e3491c918<br></p>
</blockquote>
</blockquote>
<p>AWSで受信する場合は、UDPポートで受信出来るようにするために、外部IPアドレスを持ち、セキュリティグループにUDPポート番号を設定必要があります。<br>
Jetson TX2で受信する場合は、内部IPアドレスとポート番号だけで受信出来ます。</p>
<hr>

<h4 id="_14">ストリーミング解析実行</h4>
<p>ストリーミング時はUDPポートを読み込みに指定します。
WebCamストリーミング解析コード：<a href="run_streaming.py">./run_streaming.py</a></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre>1</pre></div></td><td class=code><div class=codehilite><pre><span></span>    <span class=n>vid</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=s1>&#39;udp://localhost:8090&#39;</span><span class=p>)</span> <span class=c1># UDP Streaming</span>
</pre></div></td></tr></table></p>
<p>分類結果、スコア、物体の領域が得られるので、例えばそれを画像に描画して動画に保存することが出来ます。<br>
ロボットカーの場合は描画や動画への保存は不要ですが、停止を検出したら数秒止まる、速度を検出したら速度を変更する、等の処理を行うことになります。
<hr></p>
<h4 id="_15">動画に保存</h4>
<p>予測結果を画像に描画して動画で保存します。ここでは結果を見たいだけなので、保存する動画のFPSは適当に処理性能くらいにしておきます。<br>
Jetson TX2はメモリが不足になりやすいため、OOM(Out Of Memory)等で落ちやすいです。<br></p>
<p>Jetson TX2では、pbファイル化して検出に不要なオペレーションをそぎ落としてメモリ消費量を抑えることで、SSDの結果を動画に保存することが出来ます。<br></p>
<p>WebCamストリーミング解析コード：<a href="run_streaming.py">./run_streaming.py</a></p>
<p> <table class=codehilitetable><tr><td class=linenos><div class=linenodiv><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class=code><div class=codehilite><pre><span></span><span class=c1># FPSは処理速度を実際の見てから考慮する</span>
<span class=c1>#out = cv2.VideoWriter(OUTPUT_DIR+&#39;/output.avi&#39;, int(fourcc), fps, (int(vidw), int(vidh)))</span>
<span class=n>out</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoWriter</span><span class=p>(</span><span class=n>OUTPUT_DIR</span><span class=o>+</span><span class=s1>&#39;/output.avi&#39;</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>fourcc</span><span class=p>),</span> <span class=mf>2.1</span><span class=p>,</span> <span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>vidw</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>vidh</span><span class=p>)))</span>
    <span class=o>...</span>
            <span class=c1># 予測実行</span>
            <span class=n>rclasses</span><span class=p>,</span> <span class=n>rscores</span><span class=p>,</span> <span class=n>rbboxes</span> <span class=o>=</span> <span class=n>process_image</span><span class=p>(</span><span class=n>sess</span><span class=p>,</span><span class=n>cv_bgr</span><span class=p>)</span>
            <span class=c1># 枠を描く</span>
            <span class=n>write_bboxes</span><span class=p>(</span><span class=n>cv_bgr</span><span class=p>,</span> <span class=n>rclasses</span><span class=p>,</span> <span class=n>rscores</span><span class=p>,</span> <span class=n>rbboxes</span><span class=p>)</span>
            <span class=c1># avi動画に保存する</span>
            <span class=n>out</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>cv_bgr</span><span class=p>)</span>
</pre></div></td></tr></table></p>
<p>動画はavi形式で/notebooks/github/RobotCarAI/level3_object_detection/output/output.aviに保存されます。</p>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a></p>
<hr>

<p><a name='3'></p>
<h2 id="_16">[ディレクトリとファイルについて]</h2>
<ul>
<li>ディレクトリについて<br></li>
<li>documment/ ドキュメント関連<br></li>
<li>install_scripts/ インストールスクリプト<br></li>
<li>roadsign_data/ 道路標識データ<br></li>
<li>train_scripts/ 学習関連スクリプト<br></li>
<li>ファイルについて<br></li>
<li>README.md このファイル<br></li>
<li>scritp_define.conf ディレクトリパス等設定ファイル<br></li>
<li>run_ssd.py 検出実行コード<br></li>
<li>run_streaming.py Webcamストリーミング動画解析コード<br></li>
<li>install_scripts/install.sh インストールスクリプト<br><ul>
<li>install_scripts/install_balancap_ssd-tensorflow.sh Balancap SSD-Tensorflow ダウンロードスクリプト<br></li>
<li>install_scripts/setup_bugfix.sh Balancap SSD-Tensorflow バグ修正スクリプト<br></li>
<li>install_scripts/patch_to.sh ファイル修正スクリプト<br></li>
</ul>
</li>
<li>install_scripts/install_labelimg.sh LabelImg インストールスクリプト<br></li>
<li>model/ssd_roadsign.pb 学習済みモデル<br></li>
<li>train_scripts/setup_mytrain.sh 学習コード生成スクリプト<br></li>
<li>train_scripts/convert_PascalVOC_to_TF-Records.sh 学習データ変換スクリプト<br></li>
<li>train_scripts/train_ssd.sh 学習実行スクリプト<br></li>
<li>train_scripts/train_ssd_continue.sh 学習再開スクリプト<br></li>
<li>train_scripts/freeze_graph.sh モデル凍結スクリプト<br></li>
<li>train_scripts/add_input_x.py 学習済みcheckpointに入力名を追加するコード<br></li>
<li>train_scripts/freeze_graph.py モデル凍結コード<br></li>
</ul>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a></p>
<hr>

<p><a name='4'></p>
<h2 id="_17">[開発/学習/実行環境について]</h2>
<ul>
<li>開発環境<br></li>
<li>ラベル作成はGUIツールを使うため、画面のある環境が必要です。<br></li>
<li>学習環境<br></li>
<li>学習環境はGPUが使える環境が必要です。<br></li>
<li>実行環境<br></li>
<li>実行環境はUSBカメラが使える環境が必要です。<br></li>
<li>クラウドで実行する場合は、PCかRaspberryPi3等にUSBカメラを付けてFFMPEGを使ってカメラ映像をクラウド実行環境にUDP Streaming配信する必要があります。<br></li>
<li>USBカメラの代わりに画像ファイル、動画ファイルの読み込みも可能です。その場合はOpenCVの公式ドキュメントを参考にしてください。<br></li>
</ul>
<p><a href="#top">&lt;ページTOP&gt;</a>　<a href="#0">&lt;目次&gt;</a></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../07.level2_demo_socket/" title="Index" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前
                </span>
                Index
              </span>
            </div>
          </a>
        
        
          <a href="../09.level3_demo_socket/" title="Index" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  次
                </span>
                Index
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.9e1f3b71.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>