{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization\n",
      "0.28\n",
      "Step:0 batch_step:32 accuracy:0.54999995 full_accuracy:0.48079959 loss:27217638.37500000 time:0.77539897 clock:0.39419800000000\n",
      "Step:100 batch_step:32 accuracy:0.73000002 full_accuracy:0.78151608 loss:198372.50195312 time:12.98833394 clock:20.00354800000000\n",
      "Step:200 batch_step:32 accuracy:0.64000005 full_accuracy:0.81478649 loss:178414.77392578 time:25.16618609 clock:39.61993600000000\n",
      "Step:300 batch_step:32 accuracy:0.71999997 full_accuracy:0.82942253 loss:130843.15570068 time:37.29630208 clock:59.22087200000000\n",
      "Step:400 batch_step:32 accuracy:0.81999993 full_accuracy:0.85265905 loss:111127.12133789 time:49.43093610 clock:78.83004000000000\n",
      "Step:500 batch_step:32 accuracy:0.78000003 full_accuracy:0.87378305 loss:135634.84606934 time:61.53864408 clock:98.39048300000000\n",
      "Step:600 batch_step:32 accuracy:0.81999999 full_accuracy:0.85816634 loss:115811.69219971 time:73.66902399 clock:117.95598000000000\n",
      "Step:700 batch_step:32 accuracy:0.78000003 full_accuracy:0.82127464 loss:150201.71679688 time:85.75247693 clock:137.52061799999998\n",
      "Step:800 batch_step:32 accuracy:0.88000000 full_accuracy:0.86352283 loss:149976.43347168 time:97.86549807 clock:157.09152200000000\n",
      "Step:900 batch_step:32 accuracy:0.90000004 full_accuracy:0.87197250 loss:84162.37493896 time:109.95528793 clock:176.65349200000000\n",
      "Step:1000 batch_step:32 accuracy:0.91999996 full_accuracy:0.87861151 loss:91865.37658691 time:122.06865191 clock:196.21264099999999\n",
      "Step:1100 batch_step:32 accuracy:0.81999999 full_accuracy:0.87913960 loss:76299.71429443 time:134.16233993 clock:215.74954799999998\n",
      "Step:1200 batch_step:32 accuracy:0.84000003 full_accuracy:0.86646515 loss:114905.25561523 time:146.26704597 clock:235.32292500000000\n",
      "Step:1300 batch_step:32 accuracy:0.85000008 full_accuracy:0.86171222 loss:132006.68811035 time:158.37948990 clock:254.91786699999997\n",
      "Step:1400 batch_step:32 accuracy:0.86000001 full_accuracy:0.86299479 loss:97843.92346191 time:170.49488306 clock:274.48857600000002\n",
      "Step:1500 batch_step:32 accuracy:0.78999996 full_accuracy:0.85567671 loss:154237.70568848 time:182.59715700 clock:294.07194200000004\n",
      "Step:1600 batch_step:32 accuracy:0.79000002 full_accuracy:0.85122561 loss:122573.22106934 time:194.67189097 clock:313.64583900000002\n",
      "Step:1700 batch_step:32 accuracy:0.90000004 full_accuracy:0.88630670 loss:119342.33239746 time:206.75471997 clock:333.16924100000000\n",
      "Step:1800 batch_step:32 accuracy:0.78000003 full_accuracy:0.86382461 loss:184558.88800049 time:218.96949100 clock:352.73086400000000\n",
      "Step:1900 batch_step:32 accuracy:0.81000000 full_accuracy:0.85695928 loss:140341.00878906 time:231.03836489 clock:372.15068000000002\n",
      "Step:2000 batch_step:32 accuracy:0.81000000 full_accuracy:0.85492229 loss:144066.97619629 time:243.11312008 clock:391.56097199999999\n",
      "Step:2100 batch_step:32 accuracy:0.80999994 full_accuracy:0.85914713 loss:140131.38378906 time:255.17472601 clock:410.95340700000003\n",
      "Step:2200 batch_step:32 accuracy:0.79999995 full_accuracy:0.83840024 loss:83221.54858398 time:267.21753788 clock:430.36058300000002\n",
      "Step:2300 batch_step:32 accuracy:0.87000000 full_accuracy:0.87921500 loss:97196.28271484 time:279.27861500 clock:449.75597300000004\n",
      "Step:2400 batch_step:32 accuracy:0.92000008 full_accuracy:0.88502413 loss:79274.00762939 time:291.35807204 clock:469.19257300000004\n",
      "Step:2500 batch_step:32 accuracy:0.79000002 full_accuracy:0.83236480 loss:137349.89514160 time:303.43823409 clock:488.60536000000002\n",
      "Step:2600 batch_step:32 accuracy:0.83999997 full_accuracy:0.86925650 loss:69352.23037720 time:315.50375390 clock:508.02063500000003\n",
      "Step:2700 batch_step:32 accuracy:0.87000000 full_accuracy:0.87529194 loss:59993.68478394 time:327.53326988 clock:527.40886699999999\n",
      "Step:2800 batch_step:32 accuracy:0.88000005 full_accuracy:0.85884535 loss:168367.48364258 time:339.58791208 clock:546.80354699999998\n",
      "Step:2900 batch_step:32 accuracy:0.93000001 full_accuracy:0.89271939 loss:86638.53431702 time:351.64959288 clock:566.22847000000002\n",
      "Step:3000 batch_step:32 accuracy:0.96000004 full_accuracy:0.88547677 loss:77817.74111938 time:363.67919707 clock:585.60420499999998\n",
      "Step:3100 batch_step:32 accuracy:0.88000000 full_accuracy:0.88668394 loss:82085.57617188 time:375.72081399 clock:604.97983699999997\n",
      "Step:3200 batch_step:32 accuracy:0.84000003 full_accuracy:0.86827576 loss:134032.42687988 time:387.75312591 clock:624.35955799999999\n",
      "Step:3300 batch_step:32 accuracy:0.92000002 full_accuracy:0.89498276 loss:79869.96133423 time:399.77610707 clock:643.72631899999999\n",
      "Step:3400 batch_step:32 accuracy:0.88000000 full_accuracy:0.85386610 loss:182592.70312500 time:411.80666089 clock:663.08406500000001\n",
      "Step:3500 batch_step:32 accuracy:0.91000009 full_accuracy:0.88781554 loss:95377.74218750 time:423.83156490 clock:682.44767300000001\n",
      "Step:3600 batch_step:32 accuracy:0.93000001 full_accuracy:0.87544286 loss:101139.99371338 time:435.82843304 clock:701.77172900000005\n",
      "Step:3700 batch_step:32 accuracy:0.91000003 full_accuracy:0.89075786 loss:71339.57489014 time:447.84785509 clock:721.08920000000001\n",
      "Step:3800 batch_step:32 accuracy:0.93000007 full_accuracy:0.89362460 loss:62273.52142334 time:459.86516404 clock:740.42718400000001\n",
      "Step:3900 batch_step:32 accuracy:0.86000001 full_accuracy:0.88728744 loss:125310.44519043 time:471.87014008 clock:759.76090999999997\n",
      "Step:4000 batch_step:32 accuracy:0.96000004 full_accuracy:0.90162164 loss:56548.03390503 time:483.88674498 clock:779.09325999999999\n",
      "Step:4100 batch_step:32 accuracy:0.88000005 full_accuracy:0.89339828 loss:86227.91143799 time:495.90965796 clock:798.44475599999998\n",
      "Step:4200 batch_step:32 accuracy:0.87000006 full_accuracy:0.83658963 loss:131256.04653931 time:507.93171811 clock:817.79583600000001\n",
      "Step:4300 batch_step:32 accuracy:0.86000001 full_accuracy:0.89739686 loss:86229.38702393 time:519.94787288 clock:837.12551400000007\n",
      "Step:4400 batch_step:32 accuracy:0.95000005 full_accuracy:0.87182152 loss:90859.81451416 time:531.97112298 clock:856.45681999999999\n",
      "Step:4500 batch_step:32 accuracy:0.91000003 full_accuracy:0.90101814 loss:104136.53100586 time:543.99210000 clock:875.81560200000001\n",
      "Step:4600 batch_step:32 accuracy:0.88999999 full_accuracy:0.90101808 loss:89490.00579834 time:556.00813508 clock:895.16144700000007\n",
      "Step:4700 batch_step:32 accuracy:0.91999996 full_accuracy:0.89709502 loss:66112.69352722 time:568.02049708 clock:914.45321799999999\n",
      "Step:4800 batch_step:32 accuracy:0.82999992 full_accuracy:0.88230819 loss:99319.56921387 time:580.04223895 clock:933.80515400000002\n",
      "Step:4900 batch_step:32 accuracy:0.80999994 full_accuracy:0.86797398 loss:174053.38653564 time:592.07053900 clock:953.14980100000002\n",
      "Step:5000 batch_step:32 accuracy:0.91000003 full_accuracy:0.89309651 loss:63657.11239624 time:604.10301900 clock:972.48629100000005\n",
      "Step:5100 batch_step:32 accuracy:0.92000002 full_accuracy:0.90682721 loss:67019.21763611 time:616.11910391 clock:991.82582900000000\n",
      "Step:5200 batch_step:32 accuracy:0.97000003 full_accuracy:0.90494120 loss:99591.72875977 time:628.15217590 clock:1011.12245300000006\n",
      "Step:5300 batch_step:32 accuracy:0.90000004 full_accuracy:0.87151986 loss:105746.58514404 time:640.17713690 clock:1030.45443799999998\n",
      "Step:5400 batch_step:32 accuracy:0.93000001 full_accuracy:0.90411121 loss:91088.53906250 time:652.20742798 clock:1049.81634000000008\n",
      "Step:5500 batch_step:32 accuracy:0.87000000 full_accuracy:0.90871334 loss:86796.57318115 time:664.24476290 clock:1069.15382199999999\n",
      "Step:5600 batch_step:32 accuracy:0.88000005 full_accuracy:0.88668394 loss:94095.06497192 time:676.24945188 clock:1088.49645000000010\n",
      "Step:5700 batch_step:32 accuracy:0.84999996 full_accuracy:0.88509965 loss:90592.97375488 time:688.26418209 clock:1107.83371400000010\n",
      "Step:5800 batch_step:32 accuracy:0.97000003 full_accuracy:0.90328145 loss:115702.36987305 time:700.24721098 clock:1127.14555100000007\n",
      "Step:5900 batch_step:32 accuracy:0.92000008 full_accuracy:0.89769858 loss:84143.68634033 time:712.26096010 clock:1146.47008099999994\n",
      "Step:6000 batch_step:32 accuracy:0.87000000 full_accuracy:0.90214974 loss:55095.60256958 time:724.28252411 clock:1165.75903999999991\n",
      "Step:6100 batch_step:32 accuracy:0.86000001 full_accuracy:0.89166313 loss:112511.58648682 time:736.29741597 clock:1185.03707499999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:6200 batch_step:32 accuracy:0.94000006 full_accuracy:0.91648400 loss:67812.20520782 time:748.29987502 clock:1204.33484900000008\n",
      "Step:6300 batch_step:32 accuracy:0.82999992 full_accuracy:0.88623118 loss:155569.20513916 time:760.29787397 clock:1223.62273000000005\n",
      "Step:6400 batch_step:32 accuracy:0.87000000 full_accuracy:0.85778916 loss:138035.03601074 time:772.31049705 clock:1242.91883200000007\n",
      "Step:6500 batch_step:32 accuracy:0.90999997 full_accuracy:0.90011275 loss:58827.27789307 time:784.33189988 clock:1262.20249500000000\n",
      "Step:6600 batch_step:32 accuracy:0.86000001 full_accuracy:0.86608797 loss:99656.32624531 time:796.31812596 clock:1281.49734600000011\n",
      "Step:6700 batch_step:32 accuracy:0.95000005 full_accuracy:0.91686118 loss:95714.55496216 time:808.32205701 clock:1300.78307799999993\n",
      "Step:6800 batch_step:32 accuracy:0.94000000 full_accuracy:0.91346627 loss:63727.82961941 time:820.32117701 clock:1320.07980799999996\n",
      "Step:6900 batch_step:32 accuracy:0.93000007 full_accuracy:0.89626515 loss:63024.51068115 time:832.35160494 clock:1339.41026699999998\n",
      "Step:7000 batch_step:32 accuracy:0.93000001 full_accuracy:0.90629917 loss:77996.66760254 time:844.34894800 clock:1358.69435999999996\n",
      "Step:7100 batch_step:32 accuracy:0.89999998 full_accuracy:0.87936592 loss:96165.02285767 time:856.37880898 clock:1378.00355200000013\n",
      "Step:7200 batch_step:32 accuracy:0.95000005 full_accuracy:0.89837760 loss:66863.32211304 time:868.39461589 clock:1397.31539500000008\n",
      "Step:7300 batch_step:32 accuracy:0.81999999 full_accuracy:0.89090866 loss:101675.27301025 time:880.41761208 clock:1416.59188100000006\n",
      "Step:7400 batch_step:32 accuracy:0.92000008 full_accuracy:0.88932443 loss:90696.61987305 time:892.42626905 clock:1435.90113599999995\n",
      "Step:7500 batch_step:32 accuracy:0.90000004 full_accuracy:0.91218376 loss:48988.53752136 time:904.44605398 clock:1455.20598799999993\n",
      "Step:7600 batch_step:32 accuracy:0.90000004 full_accuracy:0.89694417 loss:90733.79211426 time:916.44971395 clock:1474.48843499999998\n",
      "Step:7700 batch_step:32 accuracy:0.92000008 full_accuracy:0.91248548 loss:80135.53527832 time:928.46968603 clock:1493.80293699999993\n",
      "Step:7800 batch_step:32 accuracy:0.92000008 full_accuracy:0.91029763 loss:95305.57507324 time:940.47148490 clock:1513.09409600000004\n",
      "Step:7900 batch_step:32 accuracy:0.90000004 full_accuracy:0.89271939 loss:158098.64825439 time:952.49469209 clock:1532.42153699999994\n",
      "Step:8000 batch_step:32 accuracy:0.89999998 full_accuracy:0.89634061 loss:63562.15759277 time:964.52201796 clock:1551.70403699999997\n",
      "Step:8100 batch_step:32 accuracy:0.83999997 full_accuracy:0.89754772 loss:61659.79092407 time:976.52833605 clock:1571.00082500000008\n",
      "Step:8200 batch_step:32 accuracy:0.91000003 full_accuracy:0.89219129 loss:108021.40411377 time:988.54490590 clock:1590.30357499999991\n",
      "Step:8300 batch_step:32 accuracy:0.94000006 full_accuracy:0.90705365 loss:76506.13876343 time:1000.55330992 clock:1609.61954300000002\n",
      "Step:8400 batch_step:32 accuracy:0.94000006 full_accuracy:0.90343225 loss:76424.29821014 time:1012.56437707 clock:1628.93538800000010\n",
      "Step:8500 batch_step:32 accuracy:0.94000006 full_accuracy:0.90946770 loss:145350.09918213 time:1024.57584190 clock:1648.26555299999995\n",
      "Step:8600 batch_step:32 accuracy:0.90000004 full_accuracy:0.89271933 loss:72722.87112427 time:1036.60246992 clock:1667.58042900000009\n",
      "Step:8700 batch_step:32 accuracy:0.89000005 full_accuracy:0.90727985 loss:57577.11920166 time:1048.61222506 clock:1686.88256100000012\n",
      "Step:8800 batch_step:32 accuracy:0.93000001 full_accuracy:0.90765709 loss:95757.85040283 time:1060.61027408 clock:1706.22282300000006\n",
      "Step:8900 batch_step:32 accuracy:0.88000000 full_accuracy:0.90622365 loss:34653.44065094 time:1072.61693001 clock:1725.54719900000009\n",
      "Step:9000 batch_step:32 accuracy:0.94000006 full_accuracy:0.90697807 loss:76757.44388062 time:1084.64910698 clock:1744.85622800000010\n",
      "Step:9100 batch_step:32 accuracy:0.94000006 full_accuracy:0.89468086 loss:81232.21997070 time:1096.67288494 clock:1764.16205600000012\n",
      "Step:9200 batch_step:32 accuracy:0.92000002 full_accuracy:0.90584642 loss:66936.08071899 time:1108.69073510 clock:1783.47650300000009\n",
      "Step:9300 batch_step:32 accuracy:0.95000005 full_accuracy:0.91195738 loss:50135.03759384 time:1120.72071600 clock:1802.79050499999994\n",
      "Step:9400 batch_step:32 accuracy:0.88000000 full_accuracy:0.90116900 loss:119789.03466797 time:1132.73536396 clock:1822.13301100000012\n",
      "Step:9500 batch_step:32 accuracy:0.89000005 full_accuracy:0.91323990 loss:199747.76278687 time:1144.75810599 clock:1841.44194799999991\n",
      "Step:9600 batch_step:32 accuracy:0.94000006 full_accuracy:0.90750617 loss:63549.27365112 time:1156.78280497 clock:1860.76613900000007\n",
      "Step:9700 batch_step:32 accuracy:0.93000001 full_accuracy:0.90101802 loss:72651.92648315 time:1168.81328201 clock:1880.08092499999998\n",
      "Step:9800 batch_step:32 accuracy:0.91000003 full_accuracy:0.90147072 loss:70081.68881226 time:1180.85735297 clock:1899.39711299999999\n",
      "Step:9900 batch_step:32 accuracy:0.91000003 full_accuracy:0.92342472 loss:41126.60981750 time:1192.88983488 clock:1918.70916600000010\n",
      "Step:10000 batch_step:32 accuracy:0.92000008 full_accuracy:0.89709508 loss:60379.01530075 time:1204.91077709 clock:1938.05027399999994\n",
      "Step:10100 batch_step:32 accuracy:0.92000002 full_accuracy:0.91482425 loss:77061.42669678 time:1216.91958189 clock:1957.36789300000009\n",
      "Step:10200 batch_step:32 accuracy:0.88000005 full_accuracy:0.89905667 loss:88797.58483887 time:1228.94813704 clock:1976.70132300000000\n",
      "Step:10300 batch_step:32 accuracy:0.87000000 full_accuracy:0.90396041 loss:98669.53839111 time:1240.96317911 clock:1996.01986800000009\n",
      "Step:10400 batch_step:32 accuracy:0.90000004 full_accuracy:0.90509200 loss:99750.22546387 time:1252.98013091 clock:2015.34107300000005\n",
      "Step:10500 batch_step:32 accuracy:0.92000008 full_accuracy:0.89988649 loss:89593.11248779 time:1264.99748993 clock:2034.69714999999997\n",
      "Step:10600 batch_step:32 accuracy:0.93000007 full_accuracy:0.90471476 loss:59298.30358887 time:1277.00358605 clock:2054.03488399999969\n",
      "Step:10700 batch_step:32 accuracy:0.90000004 full_accuracy:0.91075033 loss:53673.01855469 time:1289.00820088 clock:2073.34711699999980\n",
      "Step:10800 batch_step:32 accuracy:0.93000007 full_accuracy:0.90539378 loss:72680.15141296 time:1301.04842710 clock:2092.68547099999978\n",
      "Step:10900 batch_step:32 accuracy:0.93000001 full_accuracy:0.89219129 loss:65890.40486145 time:1313.05928111 clock:2111.99334799999997\n",
      "Step:11000 batch_step:32 accuracy:0.88000005 full_accuracy:0.90863788 loss:92925.81378174 time:1325.06994104 clock:2131.32849199999964\n",
      "Step:11100 batch_step:32 accuracy:0.96000004 full_accuracy:0.90275329 loss:60289.44143677 time:1337.10755801 clock:2150.66679599999998\n",
      "Step:11200 batch_step:32 accuracy:0.91000003 full_accuracy:0.90577102 loss:65956.53273571 time:1349.11310697 clock:2169.98247199999969\n",
      "Step:11300 batch_step:32 accuracy:0.96000004 full_accuracy:0.91444701 loss:50836.98625183 time:1361.13547707 clock:2189.33939699999974\n",
      "Step:11400 batch_step:32 accuracy:0.85999990 full_accuracy:0.89981103 loss:58812.71180725 time:1373.17509007 clock:2208.66297999999961\n",
      "Step:11500 batch_step:32 accuracy:0.90999997 full_accuracy:0.89596349 loss:59586.56277466 time:1385.20407009 clock:2227.97874199999978\n",
      "Step:11600 batch_step:32 accuracy:0.94000000 full_accuracy:0.90901506 loss:88603.09973145 time:1397.22773504 clock:2247.33452599999964\n",
      "Step:11700 batch_step:32 accuracy:0.92000008 full_accuracy:0.91889811 loss:42445.37035370 time:1409.27241492 clock:2266.66174199999978\n",
      "Step:11800 batch_step:32 accuracy:0.94000006 full_accuracy:0.91542768 loss:68875.66342163 time:1421.30467796 clock:2285.96598899999981\n",
      "Step:11900 batch_step:32 accuracy:0.91999996 full_accuracy:0.90494114 loss:102917.48881531 time:1433.34882903 clock:2305.29501099999970\n",
      "Step:12000 batch_step:32 accuracy:0.90000004 full_accuracy:0.89535987 loss:108941.66076660 time:1445.38082004 clock:2324.62455799999998\n",
      "Step:12100 batch_step:32 accuracy:0.95000005 full_accuracy:0.91618222 loss:67696.17449951 time:1457.40470099 clock:2343.94894499999964\n",
      "Step:12200 batch_step:32 accuracy:0.92000002 full_accuracy:0.91806829 loss:48635.46757507 time:1469.43217492 clock:2363.26532099999986\n",
      "Step:12300 batch_step:32 accuracy:0.94000000 full_accuracy:0.91663480 loss:49898.12604523 time:1481.45483708 clock:2382.58026599999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:12400 batch_step:32 accuracy:0.91999996 full_accuracy:0.91142929 loss:67309.00828552 time:1493.47643399 clock:2401.91812699999991\n",
      "Step:12500 batch_step:32 accuracy:0.95000005 full_accuracy:0.90207434 loss:46737.39227295 time:1505.51458001 clock:2421.23968299999979\n",
      "Step:12600 batch_step:32 accuracy:0.91000009 full_accuracy:0.90177256 loss:69300.06466675 time:1517.53881407 clock:2440.57510499999989\n",
      "Step:12700 batch_step:32 accuracy:0.89999998 full_accuracy:0.89792490 loss:67034.30297852 time:1529.55069995 clock:2459.88502899999958\n",
      "Step:12800 batch_step:32 accuracy:0.96000004 full_accuracy:0.92425460 loss:27426.65502930 time:1541.57155704 clock:2479.24178099999972\n",
      "Step:12900 batch_step:32 accuracy:0.92000002 full_accuracy:0.92168957 loss:93064.73149109 time:1553.60129809 clock:2498.56210199999987\n",
      "Step:13000 batch_step:32 accuracy:0.92000002 full_accuracy:0.91754007 loss:32805.12462616 time:1565.61449695 clock:2517.87128799999982\n",
      "Step:13100 batch_step:32 accuracy:0.95000005 full_accuracy:0.91557860 loss:52884.66306305 time:1577.62825894 clock:2537.18059199999971\n",
      "Step:13200 batch_step:32 accuracy:0.95999998 full_accuracy:0.88298720 loss:82829.99928284 time:1589.64440989 clock:2556.49401599999965\n",
      "Step:13300 batch_step:32 accuracy:0.93000001 full_accuracy:0.91369253 loss:48920.48633575 time:1601.66944408 clock:2575.83614599999964\n",
      "Step:13400 batch_step:32 accuracy:0.92000008 full_accuracy:0.91799283 loss:76096.93090916 time:1613.70617509 clock:2595.19223599999987\n",
      "Step:13500 batch_step:32 accuracy:0.98000002 full_accuracy:0.92478269 loss:57240.99871826 time:1625.72379398 clock:2614.55420699999968\n",
      "Step:13600 batch_step:32 accuracy:0.94000000 full_accuracy:0.91225916 loss:77996.67840576 time:1637.75115800 clock:2633.86105099999986\n",
      "Step:13700 batch_step:32 accuracy:0.94000006 full_accuracy:0.91301364 loss:30865.33152580 time:1649.77073908 clock:2653.19882699999971\n",
      "Step:13800 batch_step:32 accuracy:0.92000008 full_accuracy:0.91950166 loss:55393.51142883 time:1661.78830600 clock:2672.52131499999996\n",
      "Step:13900 batch_step:32 accuracy:0.96000004 full_accuracy:0.91912448 loss:28281.83496857 time:1673.80617404 clock:2691.86341299999958\n",
      "Step:14000 batch_step:32 accuracy:0.97000003 full_accuracy:0.91852093 loss:28835.24288559 time:1685.84157896 clock:2711.17370799999981\n",
      "Step:14100 batch_step:32 accuracy:0.93000007 full_accuracy:0.91897357 loss:45061.00488281 time:1697.89048195 clock:2730.49191799999971\n",
      "Step:14200 batch_step:32 accuracy:0.96000004 full_accuracy:0.91640860 loss:25556.53048372 time:1709.91527104 clock:2749.77977399999963\n",
      "Step:14300 batch_step:32 accuracy:0.94000006 full_accuracy:0.91067487 loss:36951.56895447 time:1721.95022488 clock:2769.08765199999971\n",
      "Step:14400 batch_step:32 accuracy:0.91000003 full_accuracy:0.89611429 loss:74918.26892090 time:1733.96211505 clock:2788.41895399999976\n",
      "Step:14500 batch_step:32 accuracy:0.98000002 full_accuracy:0.92508447 loss:32035.13663483 time:1745.98553109 clock:2807.73388799999975\n",
      "Step:14600 batch_step:32 accuracy:0.95000005 full_accuracy:0.90810978 loss:47143.78922272 time:1758.02112007 clock:2827.05335099999957\n",
      "Step:14700 batch_step:32 accuracy:0.93000007 full_accuracy:0.91935080 loss:84182.62863159 time:1770.03665996 clock:2846.36951199999976\n",
      "Step:14800 batch_step:32 accuracy:0.95000005 full_accuracy:0.92576349 loss:49880.19813538 time:1782.05843210 clock:2865.71764499999972\n",
      "Step:14900 batch_step:32 accuracy:0.90000010 full_accuracy:0.90818524 loss:88893.02661133 time:1794.10685492 clock:2885.05709699999989\n",
      "Step:15000 batch_step:32 accuracy:0.91999996 full_accuracy:0.92010528 loss:69416.17507935 time:1806.13977909 clock:2904.37031899999965\n",
      "Step:15100 batch_step:32 accuracy:0.95000005 full_accuracy:0.92342472 loss:100885.25822449 time:1818.17070603 clock:2923.69554699999981\n",
      "Step:15200 batch_step:32 accuracy:0.94000006 full_accuracy:0.91512597 loss:63309.30969524 time:1830.19711804 clock:2943.03357799999958\n",
      "Step:15300 batch_step:32 accuracy:0.89999998 full_accuracy:0.91618228 loss:58714.92747498 time:1842.22136307 clock:2962.37727999999970\n",
      "Step:15400 batch_step:32 accuracy:0.89000005 full_accuracy:0.91459781 loss:40340.93168640 time:1854.24931788 clock:2981.71105099999977\n",
      "Step:15500 batch_step:32 accuracy:0.93000001 full_accuracy:0.91384351 loss:27959.19490814 time:1866.26256895 clock:3001.04068999999981\n",
      "Step:15600 batch_step:32 accuracy:0.96000004 full_accuracy:0.92131233 loss:54400.44599152 time:1878.29690504 clock:3020.40703099999973\n",
      "Step:15700 batch_step:32 accuracy:0.94000000 full_accuracy:0.92055792 loss:58225.12517548 time:1890.31916595 clock:3039.69866699999966\n",
      "Step:15800 batch_step:32 accuracy:0.96000004 full_accuracy:0.92221761 loss:19425.50599670 time:1902.34095693 clock:3059.01697299999978\n",
      "Step:15900 batch_step:32 accuracy:0.95000005 full_accuracy:0.91444695 loss:62129.39991760 time:1914.37294197 clock:3078.35469899999998\n",
      "Step:16000 batch_step:32 accuracy:0.94000006 full_accuracy:0.89732134 loss:96604.76510620 time:1926.38638592 clock:3097.69665599999962\n",
      "Step:16100 batch_step:32 accuracy:0.92000008 full_accuracy:0.92236847 loss:33018.56680489 time:1938.42702889 clock:3117.04468499999984\n",
      "Step:16200 batch_step:32 accuracy:0.96000004 full_accuracy:0.90267783 loss:62472.73034668 time:1950.46388507 clock:3136.37920099999974\n",
      "Step:16300 batch_step:32 accuracy:0.97000003 full_accuracy:0.91738921 loss:33950.39175415 time:1962.50764108 clock:3155.71733999999969\n",
      "Step:16400 batch_step:32 accuracy:0.97000003 full_accuracy:0.91588038 loss:45575.09706497 time:1974.55225706 clock:3175.08003799999960\n",
      "Step:16500 batch_step:32 accuracy:0.84999990 full_accuracy:0.90373409 loss:81375.10357666 time:1986.59183598 clock:3194.43752199999972\n",
      "Step:16600 batch_step:32 accuracy:0.89000005 full_accuracy:0.90765703 loss:72749.90707397 time:1998.60661292 clock:3213.77825999999959\n",
      "Step:16700 batch_step:32 accuracy:0.93000007 full_accuracy:0.90531832 loss:49274.68812561 time:2010.63693595 clock:3233.11356599999999\n",
      "Step:16800 batch_step:32 accuracy:0.96000004 full_accuracy:0.91067487 loss:53732.09707642 time:2022.66633892 clock:3252.43480299999965\n",
      "Step:16900 batch_step:32 accuracy:0.91000009 full_accuracy:0.90773255 loss:96611.80688477 time:2034.70564294 clock:3271.77149699999973\n",
      "Step:17000 batch_step:32 accuracy:0.98000002 full_accuracy:0.92855489 loss:28811.18955231 time:2046.72895503 clock:3291.11475799999971\n",
      "Step:17100 batch_step:32 accuracy:0.92000008 full_accuracy:0.90660095 loss:50368.80210876 time:2058.75379395 clock:3310.44869799999969\n",
      "Step:17200 batch_step:32 accuracy:0.98000002 full_accuracy:0.92568803 loss:78614.34810829 time:2070.80548596 clock:3329.78421199999957\n",
      "Step:17300 batch_step:32 accuracy:0.93000007 full_accuracy:0.91323984 loss:63958.44320679 time:2082.84989500 clock:3349.15568999999959\n",
      "Step:17400 batch_step:32 accuracy:0.87000006 full_accuracy:0.90169704 loss:73751.81033325 time:2094.88660598 clock:3368.50803399999995\n",
      "Step:17500 batch_step:32 accuracy:0.91000003 full_accuracy:0.91588038 loss:75406.48976231 time:2106.94129896 clock:3387.86865199999966\n",
      "Step:17600 batch_step:32 accuracy:0.91000009 full_accuracy:0.91791737 loss:43268.55206299 time:2118.97544789 clock:3407.22269699999970\n",
      "Step:17700 batch_step:32 accuracy:0.96000004 full_accuracy:0.92433006 loss:69855.36575317 time:2131.01041007 clock:3426.58787299999995\n",
      "Step:17800 batch_step:32 accuracy:0.95000005 full_accuracy:0.92780054 loss:53369.13389587 time:2143.06117606 clock:3445.93372499999987\n",
      "Step:17900 batch_step:32 accuracy:0.94999993 full_accuracy:0.90516752 loss:75099.37796021 time:2155.10233092 clock:3465.29465399999981\n",
      "Step:18000 batch_step:32 accuracy:0.93000007 full_accuracy:0.90788352 loss:52011.77053070 time:2167.13598394 clock:3484.62014799999997\n",
      "Step:18100 batch_step:32 accuracy:0.91000003 full_accuracy:0.90448844 loss:48976.33007812 time:2179.16732287 clock:3503.97457999999961\n",
      "Step:18200 batch_step:32 accuracy:0.96000004 full_accuracy:0.93172348 loss:33993.78725433 time:2191.21785092 clock:3523.36066799999981\n",
      "Step:18300 batch_step:32 accuracy:0.92000002 full_accuracy:0.92168963 loss:70257.02837372 time:2203.27202106 clock:3542.70797999999968\n",
      "Step:18400 batch_step:32 accuracy:0.95999998 full_accuracy:0.92334938 loss:43002.13427925 time:2215.32387400 clock:3562.06137300000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:18500 batch_step:32 accuracy:0.93000001 full_accuracy:0.92402828 loss:48083.28616333 time:2227.36967397 clock:3581.42904199999975\n",
      "Step:18600 batch_step:32 accuracy:0.96999997 full_accuracy:0.91346616 loss:68409.78869629 time:2239.43007994 clock:3600.78170899999986\n",
      "Step:18700 batch_step:32 accuracy:0.96000004 full_accuracy:0.93134636 loss:34278.26385307 time:2251.45469999 clock:3620.13099899999997\n",
      "Step:18800 batch_step:32 accuracy:0.96000004 full_accuracy:0.91995430 loss:39173.38616943 time:2263.50131607 clock:3639.49476399999958\n",
      "Step:18900 batch_step:32 accuracy:0.98000002 full_accuracy:0.91686118 loss:72130.59423065 time:2275.54572105 clock:3658.85641099999975\n",
      "Step:19000 batch_step:32 accuracy:0.93000001 full_accuracy:0.92055786 loss:25344.69897270 time:2287.57794189 clock:3678.17417299999988\n",
      "Step:19100 batch_step:32 accuracy:0.96999997 full_accuracy:0.92101055 loss:62099.53900146 time:2299.61958289 clock:3697.51960199999985\n",
      "Step:19200 batch_step:32 accuracy:0.95000005 full_accuracy:0.92221761 loss:53158.60645676 time:2311.66159797 clock:3716.87473699999964\n",
      "Step:19300 batch_step:32 accuracy:0.91000003 full_accuracy:0.91633308 loss:47648.12393188 time:2323.71832895 clock:3736.26456399999961\n",
      "Step:19400 batch_step:32 accuracy:0.94999999 full_accuracy:0.92538625 loss:37461.37243176 time:2335.74659491 clock:3755.61564099999987\n",
      "Step:19500 batch_step:32 accuracy:0.99000001 full_accuracy:0.92636693 loss:43318.21844101 time:2347.78751588 clock:3774.97224899999992\n",
      "Step:19600 batch_step:32 accuracy:0.98000002 full_accuracy:0.93202525 loss:19330.52327368 time:2359.83328509 clock:3794.34586700000000\n",
      "Step:19700 batch_step:32 accuracy:0.88000000 full_accuracy:0.91203290 loss:41451.11212158 time:2371.87223196 clock:3813.71882699999969\n",
      "Step:19800 batch_step:32 accuracy:0.99000001 full_accuracy:0.93096906 loss:20424.22802353 time:2383.92931890 clock:3833.06797399999959\n",
      "Step:19900 batch_step:32 accuracy:0.97000003 full_accuracy:0.92863029 loss:21701.78376007 time:2395.97360206 clock:3852.41789199999994\n",
      "Step:20000 batch_step:32 accuracy:0.91000003 full_accuracy:0.92576349 loss:46598.55001831 time:2408.01707196 clock:3871.77772899999991\n",
      "Step:20100 batch_step:32 accuracy:0.98000002 full_accuracy:0.92621613 loss:38053.94167328 time:2420.06580400 clock:3891.11211499999990\n",
      "Step:20200 batch_step:32 accuracy:0.92000008 full_accuracy:0.90426219 loss:75786.79566956 time:2432.07976294 clock:3910.45435999999972\n",
      "Step:20300 batch_step:32 accuracy:0.95000005 full_accuracy:0.91225916 loss:45558.20591736 time:2444.12352610 clock:3929.81832899999972\n",
      "Step:20400 batch_step:32 accuracy:0.92000008 full_accuracy:0.92161405 loss:54479.54965973 time:2456.16552901 clock:3949.18737399999964\n",
      "Step:20500 batch_step:32 accuracy:0.97000003 full_accuracy:0.91935080 loss:62846.60554504 time:2468.19333696 clock:3968.53756299999986\n",
      "Step:20600 batch_step:32 accuracy:0.96000004 full_accuracy:0.92802680 loss:66530.74319458 time:2480.23708105 clock:3987.88162499999999\n",
      "Step:20700 batch_step:32 accuracy:0.95000005 full_accuracy:0.92282116 loss:34288.87967777 time:2492.29297495 clock:4007.22173899999962\n",
      "Step:20800 batch_step:32 accuracy:0.93000001 full_accuracy:0.92583889 loss:48434.11593628 time:2504.34502196 clock:4026.58979199999976\n",
      "Step:20900 batch_step:32 accuracy:0.94000006 full_accuracy:0.92666870 loss:36066.69681549 time:2516.39626408 clock:4045.95751599999994\n",
      "Step:21000 batch_step:32 accuracy:0.91000009 full_accuracy:0.92636698 loss:23854.14557242 time:2528.43953800 clock:4065.32711699999982\n",
      "Step:21100 batch_step:32 accuracy:0.94999999 full_accuracy:0.93428856 loss:20797.60729456 time:2540.48755598 clock:4084.70542399999977\n",
      "Step:21200 batch_step:32 accuracy:0.98000002 full_accuracy:0.92742318 loss:17587.95237923 time:2552.54194307 clock:4104.07716699999946\n",
      "Step:21300 batch_step:32 accuracy:0.97999996 full_accuracy:0.93270421 loss:35652.46838570 time:2564.59365702 clock:4123.45067800000015\n",
      "Step:21400 batch_step:32 accuracy:0.85999990 full_accuracy:0.92033160 loss:82385.98859358 time:2576.65035605 clock:4142.79276699999991\n",
      "Step:21500 batch_step:32 accuracy:0.95000005 full_accuracy:0.92855489 loss:21160.95978069 time:2588.66523099 clock:4162.13492200000019\n",
      "Step:21600 batch_step:32 accuracy:0.96000004 full_accuracy:0.93028998 loss:21733.54344940 time:2600.71670508 clock:4181.51250900000014\n",
      "Step:21700 batch_step:32 accuracy:0.95999998 full_accuracy:0.92893207 loss:33364.31860638 time:2612.76573896 clock:4200.87085599999955\n",
      "Step:21800 batch_step:32 accuracy:0.95000005 full_accuracy:0.92900747 loss:65091.86767578 time:2624.82498407 clock:4220.24274299999979\n",
      "Step:21900 batch_step:32 accuracy:0.96000004 full_accuracy:0.92161405 loss:40945.42072296 time:2636.86605096 clock:4239.58415400000013\n",
      "Step:22000 batch_step:32 accuracy:0.96000004 full_accuracy:0.90675175 loss:37014.43675232 time:2648.88968492 clock:4258.94233699999950\n",
      "Step:22100 batch_step:32 accuracy:0.96000004 full_accuracy:0.93142164 loss:72173.81091309 time:2660.91396904 clock:4278.28659199999947\n",
      "Step:22200 batch_step:32 accuracy:1.00000000 full_accuracy:0.92968655 loss:33947.96496582 time:2672.98543000 clock:4297.62787500000013\n",
      "Step:22300 batch_step:32 accuracy:0.96000004 full_accuracy:0.92704600 loss:43383.84469986 time:2685.04911804 clock:4317.00914000000012\n",
      "Step:22400 batch_step:32 accuracy:0.93000007 full_accuracy:0.92357564 loss:44152.97608948 time:2697.07472110 clock:4336.37509299999965\n",
      "Step:22500 batch_step:32 accuracy:0.90000010 full_accuracy:0.92757404 loss:53601.33264160 time:2709.10098791 clock:4355.73192800000015\n",
      "Step:22600 batch_step:32 accuracy:0.97000003 full_accuracy:0.92455637 loss:30704.58446121 time:2721.13167596 clock:4375.09242300000005\n",
      "Step:22700 batch_step:32 accuracy:0.96000004 full_accuracy:0.92704600 loss:43472.51171684 time:2733.19791102 clock:4394.47272999999950\n",
      "Step:22800 batch_step:32 accuracy:1.00000000 full_accuracy:0.93277973 loss:15736.76358795 time:2745.23244691 clock:4413.83338199999980\n",
      "Step:22900 batch_step:32 accuracy:0.88000000 full_accuracy:0.92161411 loss:53352.50257301 time:2757.29939699 clock:4433.20481399999971\n",
      "Step:23000 batch_step:32 accuracy:0.94000000 full_accuracy:0.92568803 loss:44538.24521255 time:2769.33649707 clock:4452.54522600000018\n",
      "Step:23100 batch_step:32 accuracy:0.94000006 full_accuracy:0.93021458 loss:58212.41986084 time:2781.37701607 clock:4471.91347099999984\n",
      "Step:23200 batch_step:32 accuracy:0.96000004 full_accuracy:0.93270421 loss:38408.80639458 time:2793.42025304 clock:4491.28559099999984\n",
      "Step:23300 batch_step:32 accuracy:0.93000007 full_accuracy:0.92689508 loss:42409.18257141 time:2805.44380498 clock:4510.61920300000020\n",
      "Step:23400 batch_step:32 accuracy:0.95000005 full_accuracy:0.92508447 loss:26472.72845268 time:2817.48008704 clock:4529.97846299999946\n",
      "Step:23500 batch_step:32 accuracy:0.94000006 full_accuracy:0.92885661 loss:37125.28593397 time:2829.52225399 clock:4549.33937999999944\n",
      "Step:23600 batch_step:32 accuracy:0.93000007 full_accuracy:0.92327374 loss:27474.05517578 time:2841.55114102 clock:4568.69305299999996\n",
      "Step:23700 batch_step:32 accuracy:0.97000003 full_accuracy:0.92674416 loss:30301.46856689 time:2853.58286691 clock:4588.03862099999969\n",
      "Step:23800 batch_step:32 accuracy:0.86999995 full_accuracy:0.88419431 loss:55988.01021957 time:2865.60923290 clock:4607.41420800000014\n",
      "Step:23900 batch_step:32 accuracy:0.90999997 full_accuracy:0.92184043 loss:33680.75419617 time:2877.63668203 clock:4626.74478799999997\n",
      "Step:24000 batch_step:32 accuracy:0.97000003 full_accuracy:0.92817765 loss:26486.54355240 time:2889.69855094 clock:4646.12649400000009\n",
      "Step:24100 batch_step:32 accuracy:0.93000007 full_accuracy:0.93421316 loss:24585.87306976 time:2901.74496388 clock:4665.48520899999949\n",
      "Step:24200 batch_step:32 accuracy:0.96000004 full_accuracy:0.92991287 loss:56677.48778534 time:2913.80813003 clock:4684.81951899999967\n",
      "Step:24300 batch_step:32 accuracy:0.98000002 full_accuracy:0.93345869 loss:49167.26499939 time:2925.86596990 clock:4704.17818199999965\n",
      "Step:24400 batch_step:32 accuracy:0.91000003 full_accuracy:0.91406977 loss:42714.11077881 time:2937.91153908 clock:4723.54070599999977\n",
      "Step:24500 batch_step:32 accuracy:0.98000002 full_accuracy:0.93391138 loss:13164.87278366 time:2949.94741297 clock:4742.92709199999990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:24600 batch_step:32 accuracy:0.90000010 full_accuracy:0.92825305 loss:60372.86281967 time:2961.99761891 clock:4762.29473299999972\n",
      "Step:24700 batch_step:32 accuracy:0.94000000 full_accuracy:0.92946017 loss:75327.25369263 time:2974.05062008 clock:4781.65519299999960\n",
      "Step:24800 batch_step:32 accuracy:0.97000003 full_accuracy:0.92101049 loss:59385.36941528 time:2986.09853697 clock:4801.01183899999978\n",
      "Step:24900 batch_step:32 accuracy:0.97000003 full_accuracy:0.93519390 loss:28031.35122013 time:2998.15067601 clock:4820.37651899999946\n",
      "Step:25000 batch_step:32 accuracy:0.96000004 full_accuracy:0.93081814 loss:30075.86380005 time:3010.20012403 clock:4839.73689199999990\n",
      "Step:25100 batch_step:32 accuracy:0.95000005 full_accuracy:0.93240249 loss:15735.98122001 time:3022.27393103 clock:4859.08478399999967\n",
      "Step:25200 batch_step:32 accuracy:0.92000008 full_accuracy:0.92417914 loss:21993.03710556 time:3034.32479000 clock:4878.44774899999993\n",
      "Step:25300 batch_step:32 accuracy:0.95999998 full_accuracy:0.92968655 loss:54551.02960587 time:3046.36693907 clock:4897.80656999999974\n",
      "Step:25400 batch_step:32 accuracy:0.95999998 full_accuracy:0.93632561 loss:28113.23760414 time:3058.39371610 clock:4917.16766399999960\n",
      "Step:25500 batch_step:32 accuracy:0.96000004 full_accuracy:0.93300605 loss:62679.05966187 time:3070.42969203 clock:4936.50743499999953\n",
      "Step:25600 batch_step:32 accuracy:0.95000005 full_accuracy:0.92470729 loss:26069.87898254 time:3082.44740105 clock:4955.86281899999994\n",
      "Step:25700 batch_step:32 accuracy:0.90000010 full_accuracy:0.92327380 loss:43622.26540375 time:3094.49112201 clock:4975.21272099999987\n",
      "Step:25800 batch_step:32 accuracy:0.95999998 full_accuracy:0.92591429 loss:54396.19476700 time:3106.55873203 clock:4994.60085600000002\n",
      "Step:25900 batch_step:32 accuracy:0.93000001 full_accuracy:0.93134624 loss:82240.45542145 time:3118.59534097 clock:5013.96983300000011\n",
      "Step:26000 batch_step:32 accuracy:0.96000004 full_accuracy:0.93029010 loss:55489.53836060 time:3130.64930701 clock:5033.31790699999965\n",
      "Step:26100 batch_step:32 accuracy:0.95000005 full_accuracy:0.93338323 loss:47058.66577435 time:3142.68323803 clock:5052.65565799999968\n",
      "Step:26200 batch_step:32 accuracy:0.98999995 full_accuracy:0.93896604 loss:9454.22097254 time:3154.73653293 clock:5072.03183900000022\n",
      "Step:26300 batch_step:32 accuracy:0.95000005 full_accuracy:0.93700451 loss:22310.65094493 time:3166.79448891 clock:5091.39283499999965\n",
      "Step:26400 batch_step:32 accuracy:0.97000003 full_accuracy:0.92742318 loss:20057.83977675 time:3178.82039595 clock:5110.72401099999934\n",
      "Step:26500 batch_step:32 accuracy:0.94000006 full_accuracy:0.91135383 loss:104555.32441711 time:3190.85444498 clock:5130.07706899999994\n",
      "Step:26600 batch_step:32 accuracy:0.83999997 full_accuracy:0.91987896 loss:46183.86306763 time:3202.89003491 clock:5149.43235300000015\n",
      "Step:26700 batch_step:32 accuracy:0.97000003 full_accuracy:0.92983735 loss:64080.78304386 time:3214.94909692 clock:5168.79433199999949\n",
      "Step:26800 batch_step:32 accuracy:0.98000002 full_accuracy:0.92742324 loss:19466.84375894 time:3226.97950006 clock:5188.17895200000021\n",
      "Step:26900 batch_step:32 accuracy:0.98000002 full_accuracy:0.92930925 loss:27829.19508362 time:3239.03642297 clock:5207.53838199999973\n",
      "Step:27000 batch_step:32 accuracy:0.92000008 full_accuracy:0.92410362 loss:63052.98197937 time:3251.07777596 clock:5226.89380499999970\n",
      "Step:27100 batch_step:32 accuracy:0.97000003 full_accuracy:0.91791743 loss:29771.14216614 time:3263.11551404 clock:5246.24441800000022\n",
      "Step:27200 batch_step:32 accuracy:0.95999998 full_accuracy:0.93873972 loss:39405.53872681 time:3275.14946890 clock:5265.59566399999949\n",
      "Step:27300 batch_step:32 accuracy:0.90999997 full_accuracy:0.91965258 loss:39834.51746178 time:3287.18735099 clock:5284.95327799999995\n",
      "Step:27400 batch_step:32 accuracy:0.94000000 full_accuracy:0.92433006 loss:35184.56998777 time:3299.22565603 clock:5304.31236900000022\n",
      "Step:27500 batch_step:32 accuracy:0.98999995 full_accuracy:0.93896604 loss:31715.05291939 time:3311.24379897 clock:5323.66201300000012\n",
      "Step:27600 batch_step:32 accuracy:0.96999997 full_accuracy:0.93730623 loss:12912.34229088 time:3323.28038096 clock:5343.02700000000004\n",
      "Step:27700 batch_step:32 accuracy:0.96000004 full_accuracy:0.93655181 loss:21203.79744387 time:3335.32750702 clock:5362.39325999999983\n",
      "Step:27800 batch_step:32 accuracy:0.94000000 full_accuracy:0.93421316 loss:38791.69535828 time:3347.37283397 clock:5381.75549799999953\n",
      "Step:27900 batch_step:32 accuracy:0.96999997 full_accuracy:0.93572193 loss:38449.50040817 time:3359.41907811 clock:5401.11370399999942\n",
      "Step:28000 batch_step:32 accuracy:0.98999995 full_accuracy:0.93753260 loss:26916.90744114 time:3371.44329309 clock:5420.44271899999967\n",
      "Step:28100 batch_step:32 accuracy:0.99000001 full_accuracy:0.93511844 loss:32602.79797363 time:3383.47750807 clock:5439.75260499999968\n",
      "Step:28200 batch_step:32 accuracy:0.96000004 full_accuracy:0.93474120 loss:32246.42195702 time:3395.51724792 clock:5459.08746499999961\n",
      "Step:28300 batch_step:32 accuracy:0.96000004 full_accuracy:0.92780042 loss:45957.62724304 time:3407.55857897 clock:5478.45918900000015\n",
      "Step:28400 batch_step:32 accuracy:0.94000000 full_accuracy:0.92289662 loss:27321.14999962 time:3419.61213994 clock:5497.83186099999966\n",
      "Step:28500 batch_step:32 accuracy:0.97000003 full_accuracy:0.93534482 loss:15020.79587173 time:3431.65955091 clock:5517.18300699999963\n",
      "Step:28600 batch_step:32 accuracy:0.92000002 full_accuracy:0.92531073 loss:40181.96693611 time:3443.70315003 clock:5536.54883499999960\n",
      "Step:28700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94424701 loss:5725.17180240 time:3455.74520397 clock:5555.89166099999966\n",
      "Step:28800 batch_step:32 accuracy:0.98000002 full_accuracy:0.94009769 loss:25427.63987350 time:3467.79772305 clock:5575.24210799999946\n",
      "Step:28900 batch_step:32 accuracy:0.98000002 full_accuracy:0.94281369 loss:11913.29035568 time:3479.84345794 clock:5594.59589700000015\n",
      "Step:29000 batch_step:32 accuracy:0.98000002 full_accuracy:0.93270427 loss:14784.48033905 time:3491.87372303 clock:5613.93095999999969\n",
      "Step:29100 batch_step:32 accuracy:0.99000001 full_accuracy:0.93466574 loss:31904.78920746 time:3503.91457200 clock:5633.30021599999964\n",
      "Step:29200 batch_step:32 accuracy:0.96000004 full_accuracy:0.92832857 loss:33043.97644424 time:3515.95148706 clock:5652.63913599999978\n",
      "Step:29300 batch_step:32 accuracy:0.93000007 full_accuracy:0.93036550 loss:39868.65062523 time:3527.99943900 clock:5672.00979800000005\n",
      "Step:29400 batch_step:32 accuracy:0.96000004 full_accuracy:0.92493361 loss:33523.80258942 time:3540.03370404 clock:5691.34642999999960\n",
      "Step:29500 batch_step:32 accuracy:1.00000000 full_accuracy:0.93828702 loss:43034.49066591 time:3552.05858994 clock:5710.69823699999961\n",
      "Step:29600 batch_step:32 accuracy:0.94000000 full_accuracy:0.93376046 loss:31664.12210083 time:3564.07552409 clock:5730.05206799999996\n",
      "Step:29700 batch_step:32 accuracy:0.99000001 full_accuracy:0.93059182 loss:31017.13341331 time:3576.10328388 clock:5749.42208799999935\n",
      "Step:29800 batch_step:32 accuracy:0.91000003 full_accuracy:0.93376046 loss:56806.50073338 time:3588.14061499 clock:5768.80615599999965\n",
      "Step:29900 batch_step:32 accuracy:0.93000007 full_accuracy:0.90924144 loss:50281.65320587 time:3600.16579604 clock:5788.14987199999996\n",
      "Step:30000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94168198 loss:14514.99809551 time:3612.19897509 clock:5807.52008200000000\n",
      "Step:30100 batch_step:32 accuracy:0.99000001 full_accuracy:0.93602377 loss:7843.21771526 time:3624.22469997 clock:5826.88194599999952\n",
      "Step:30200 batch_step:32 accuracy:0.95999998 full_accuracy:0.93889058 loss:18264.02016449 time:3636.25187206 clock:5846.22732999999971\n",
      "Step:30300 batch_step:32 accuracy:0.98000002 full_accuracy:0.93753254 loss:16399.16379976 time:3648.28768706 clock:5865.58361599999989\n",
      "Step:30400 batch_step:32 accuracy:0.98000002 full_accuracy:0.93964505 loss:34512.26444626 time:3660.30579901 clock:5884.91367399999945\n",
      "Step:30500 batch_step:32 accuracy:0.94999999 full_accuracy:0.93926781 loss:13450.88429928 time:3672.32817507 clock:5904.27426699999978\n",
      "Step:30600 batch_step:32 accuracy:0.91000003 full_accuracy:0.92644250 loss:41379.86060810 time:3684.36191392 clock:5923.63184999999976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:30700 batch_step:32 accuracy:0.97000003 full_accuracy:0.93617463 loss:19223.95267010 time:3696.41098905 clock:5942.97939700000006\n",
      "Step:30800 batch_step:32 accuracy:0.99000001 full_accuracy:0.93104452 loss:23518.03661346 time:3708.46229506 clock:5962.33620400000018\n",
      "Step:30900 batch_step:32 accuracy:0.99000001 full_accuracy:0.93798524 loss:18158.30619526 time:3720.50848293 clock:5981.68890599999941\n",
      "Step:31000 batch_step:32 accuracy:0.96000004 full_accuracy:0.93579745 loss:39706.14782763 time:3732.55738306 clock:6001.04689499999949\n",
      "Step:31100 batch_step:32 accuracy:0.94000006 full_accuracy:0.92802674 loss:38411.27399349 time:3744.58707500 clock:6020.40169999999944\n",
      "Step:31200 batch_step:32 accuracy:0.98000002 full_accuracy:0.93715543 loss:22189.75479555 time:3756.63003707 clock:6039.75590899999952\n",
      "Step:31300 batch_step:32 accuracy:0.98000002 full_accuracy:0.93655187 loss:29589.82417953 time:3768.65692806 clock:6059.09946099999979\n",
      "Step:31400 batch_step:32 accuracy:0.96000004 full_accuracy:0.93006366 loss:33582.60694885 time:3780.68983197 clock:6078.41546699999981\n",
      "Step:31500 batch_step:32 accuracy:0.93000001 full_accuracy:0.93881512 loss:25393.04585409 time:3792.72551394 clock:6097.75188900000012\n",
      "Step:31600 batch_step:32 accuracy:0.98000002 full_accuracy:0.93919235 loss:30030.73889375 time:3804.75133204 clock:6117.10414499999933\n",
      "Step:31700 batch_step:32 accuracy:0.97000003 full_accuracy:0.93466580 loss:21285.32630730 time:3816.76718307 clock:6136.45956099999967\n",
      "Step:31800 batch_step:32 accuracy:0.99000001 full_accuracy:0.93994683 loss:32609.24120522 time:3828.78459811 clock:6155.78091200000017\n",
      "Step:31900 batch_step:32 accuracy:0.97000003 full_accuracy:0.92357564 loss:38283.68830299 time:3840.82009411 clock:6175.12196899999981\n",
      "Step:32000 batch_step:32 accuracy:0.95000005 full_accuracy:0.94017315 loss:30712.08522224 time:3852.82513905 clock:6194.46020599999974\n",
      "Step:32100 batch_step:32 accuracy:0.94999999 full_accuracy:0.93459034 loss:47747.76843262 time:3864.87466002 clock:6213.79710100000011\n",
      "Step:32200 batch_step:32 accuracy:0.95000005 full_accuracy:0.93708003 loss:36162.24999237 time:3876.91500401 clock:6233.14155799999935\n",
      "Step:32300 batch_step:32 accuracy:1.00000000 full_accuracy:0.94651031 loss:7751.71972561 time:3888.94276404 clock:6252.46572299999934\n",
      "Step:32400 batch_step:32 accuracy:0.94000006 full_accuracy:0.92568803 loss:43408.05451584 time:3900.96602798 clock:6271.81333099999938\n",
      "Step:32500 batch_step:32 accuracy:0.94000006 full_accuracy:0.93790984 loss:26979.37777328 time:3913.02624297 clock:6291.17063299999973\n",
      "Step:32600 batch_step:32 accuracy:0.97000003 full_accuracy:0.93881512 loss:38747.89863586 time:3925.06235194 clock:6310.51311799999985\n",
      "Step:32700 batch_step:32 accuracy:0.93000007 full_accuracy:0.93836242 loss:22618.03143954 time:3937.10965300 clock:6329.86121999999978\n",
      "Step:32800 batch_step:32 accuracy:0.95000005 full_accuracy:0.93851340 loss:13142.92560196 time:3949.16297007 clock:6349.22810200000004\n",
      "Step:32900 batch_step:32 accuracy:0.99000001 full_accuracy:0.94296455 loss:6827.38347626 time:3961.20850611 clock:6368.57535199999984\n",
      "Step:33000 batch_step:32 accuracy:0.99000001 full_accuracy:0.93866426 loss:40802.95551050 time:3973.25435710 clock:6387.94369399999960\n",
      "Step:33100 batch_step:32 accuracy:0.97000003 full_accuracy:0.93496758 loss:27900.50598335 time:3985.26900601 clock:6407.27910400000019\n",
      "Step:33200 batch_step:32 accuracy:0.98000002 full_accuracy:0.93738174 loss:11191.24611396 time:3997.31755495 clock:6426.61294499999985\n",
      "Step:33300 batch_step:32 accuracy:0.96000004 full_accuracy:0.93572199 loss:23785.02709961 time:4009.33726406 clock:6445.94677499999943\n",
      "Step:33400 batch_step:32 accuracy:0.93000007 full_accuracy:0.93670273 loss:13995.14249527 time:4021.37582898 clock:6465.30155000000013\n",
      "Step:33500 batch_step:32 accuracy:0.86000001 full_accuracy:0.91512603 loss:42941.61565232 time:4033.39327693 clock:6484.65602299999955\n",
      "Step:33600 batch_step:32 accuracy:0.94000006 full_accuracy:0.93421304 loss:34035.10270882 time:4045.43731308 clock:6503.99638299999970\n",
      "Step:33700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94251192 loss:6829.50124645 time:4057.48925900 clock:6523.38605499999994\n",
      "Step:33800 batch_step:32 accuracy:0.98000002 full_accuracy:0.93813610 loss:26748.10580921 time:4069.50761294 clock:6542.72762799999964\n",
      "Step:33900 batch_step:32 accuracy:0.95999998 full_accuracy:0.93579739 loss:12908.00429916 time:4081.54821610 clock:6562.07482499999969\n",
      "Step:34000 batch_step:32 accuracy:0.97999996 full_accuracy:0.93353409 loss:19659.28481379 time:4093.58234000 clock:6581.44406699999945\n",
      "Step:34100 batch_step:32 accuracy:0.97000003 full_accuracy:0.94039935 loss:8233.32640219 time:4105.63492799 clock:6600.78830999999991\n",
      "Step:34200 batch_step:32 accuracy:0.98000002 full_accuracy:0.93421304 loss:16447.93158340 time:4117.65108299 clock:6620.11316999999963\n",
      "Step:34300 batch_step:32 accuracy:0.88999999 full_accuracy:0.91135383 loss:109841.15106201 time:4129.67111397 clock:6639.44798300000002\n",
      "Step:34400 batch_step:32 accuracy:0.97999996 full_accuracy:0.93564653 loss:15011.91312790 time:4141.70966196 clock:6658.78130499999952\n",
      "Step:34500 batch_step:32 accuracy:0.93000007 full_accuracy:0.93889052 loss:16295.82562828 time:4153.74828005 clock:6678.11489299999994\n",
      "Step:34600 batch_step:32 accuracy:0.98000002 full_accuracy:0.94062579 loss:35452.26420975 time:4165.78580689 clock:6697.46682599999986\n",
      "Step:34700 batch_step:32 accuracy:0.97999996 full_accuracy:0.94145572 loss:22516.39055800 time:4177.81889105 clock:6716.81381999999940\n",
      "Step:34800 batch_step:32 accuracy:0.97000003 full_accuracy:0.93715537 loss:34529.13455009 time:4189.85981488 clock:6736.18248200000016\n",
      "Step:34900 batch_step:32 accuracy:0.99000001 full_accuracy:0.94243646 loss:12102.36297703 time:4201.89498401 clock:6755.53079600000001\n",
      "Step:35000 batch_step:32 accuracy:0.97000003 full_accuracy:0.93066728 loss:23442.45651484 time:4213.94179392 clock:6774.88280699999996\n",
      "Step:35100 batch_step:32 accuracy:0.99000001 full_accuracy:0.93730628 loss:18032.22463417 time:4225.98020697 clock:6794.20664200000010\n",
      "Step:35200 batch_step:32 accuracy:0.98000002 full_accuracy:0.93640095 loss:15965.71091807 time:4238.01651311 clock:6813.54589099999976\n",
      "Step:35300 batch_step:32 accuracy:0.98000002 full_accuracy:0.93692905 loss:19747.14391565 time:4250.06030703 clock:6832.90051399999993\n",
      "Step:35400 batch_step:32 accuracy:1.00000000 full_accuracy:0.94545418 loss:24997.99604797 time:4262.10056496 clock:6852.26879000000008\n",
      "Step:35500 batch_step:32 accuracy:0.99000001 full_accuracy:0.93270427 loss:21329.64672852 time:4274.13066506 clock:6871.60554200000024\n",
      "Step:35600 batch_step:32 accuracy:0.94000000 full_accuracy:0.93134624 loss:60922.74146271 time:4286.17476797 clock:6890.93827199999942\n",
      "Step:35700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94017315 loss:20791.01815796 time:4298.18234205 clock:6910.26683799999955\n",
      "Step:35800 batch_step:32 accuracy:0.98000002 full_accuracy:0.92251939 loss:44312.20782471 time:4310.21632910 clock:6929.62487899999996\n",
      "Step:35900 batch_step:32 accuracy:0.98000002 full_accuracy:0.93964505 loss:24594.93437386 time:4322.25489807 clock:6948.98038999999972\n",
      "Step:36000 batch_step:32 accuracy:0.99000001 full_accuracy:0.93692905 loss:22415.33398819 time:4334.30096006 clock:6968.33086899999944\n",
      "Step:36100 batch_step:32 accuracy:0.95000005 full_accuracy:0.93783444 loss:9600.57801652 time:4346.35381198 clock:6987.66726500000004\n",
      "Step:36200 batch_step:32 accuracy:0.97999996 full_accuracy:0.93798524 loss:15230.84056473 time:4358.40406108 clock:7006.98504400000002\n",
      "Step:36300 batch_step:32 accuracy:0.96000004 full_accuracy:0.93624997 loss:25515.34386253 time:4370.43513703 clock:7026.34858399999939\n",
      "Step:36400 batch_step:32 accuracy:1.00000000 full_accuracy:0.94319087 loss:5390.38459158 time:4382.47121906 clock:7045.74350799999957\n",
      "Step:36500 batch_step:32 accuracy:0.95999998 full_accuracy:0.92463183 loss:25296.42558670 time:4394.50929308 clock:7065.11585999999988\n",
      "Step:36600 batch_step:32 accuracy:0.98000002 full_accuracy:0.94379443 loss:24955.05965996 time:4406.55911493 clock:7084.46181299999989\n",
      "Step:36700 batch_step:32 accuracy:0.95000005 full_accuracy:0.94062573 loss:9971.67692044 time:4418.57923698 clock:7103.81262699999934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:36800 batch_step:32 accuracy:0.99000001 full_accuracy:0.94213474 loss:14005.27714729 time:4430.60602689 clock:7123.18137800000022\n",
      "Step:36900 batch_step:32 accuracy:0.98000002 full_accuracy:0.94002217 loss:15130.32874382 time:4442.65471792 clock:7142.56081600000016\n",
      "Step:37000 batch_step:32 accuracy:0.97999996 full_accuracy:0.94183290 loss:20051.42022991 time:4454.69239807 clock:7161.90886799999953\n",
      "Step:37100 batch_step:32 accuracy:0.95000005 full_accuracy:0.93511844 loss:14846.78307247 time:4466.71398592 clock:7181.24587400000019\n",
      "Step:37200 batch_step:32 accuracy:0.97000003 full_accuracy:0.94273812 loss:14213.23161316 time:4478.73460102 clock:7200.60273999999936\n",
      "Step:37300 batch_step:32 accuracy:0.97000003 full_accuracy:0.93338323 loss:30588.59641266 time:4490.76414490 clock:7219.95682799999940\n",
      "Step:37400 batch_step:32 accuracy:0.97000003 full_accuracy:0.93670273 loss:31356.48916435 time:4502.79240489 clock:7239.31368199999997\n",
      "Step:37500 batch_step:32 accuracy:1.00000000 full_accuracy:0.94273818 loss:20405.84838486 time:4514.81234002 clock:7258.67480100000012\n",
      "Step:37600 batch_step:32 accuracy:0.97000003 full_accuracy:0.94122934 loss:11556.36884547 time:4526.84084988 clock:7278.04844899999989\n",
      "Step:37700 batch_step:32 accuracy:0.97999996 full_accuracy:0.93866420 loss:24279.38362885 time:4538.84182310 clock:7297.39260899999954\n",
      "Step:37800 batch_step:32 accuracy:0.98000002 full_accuracy:0.93707991 loss:80726.83835220 time:4550.88016605 clock:7316.76370099999986\n",
      "Step:37900 batch_step:32 accuracy:0.94999999 full_accuracy:0.93383586 loss:27325.63518810 time:4562.92029405 clock:7336.13329100000010\n",
      "Step:38000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94183284 loss:20148.44778442 time:4574.95476103 clock:7355.47897099999955\n",
      "Step:38100 batch_step:32 accuracy:0.96000004 full_accuracy:0.93066728 loss:23118.98712540 time:4586.96319699 clock:7374.80434499999956\n",
      "Step:38200 batch_step:32 accuracy:0.97000003 full_accuracy:0.93368500 loss:47014.82833743 time:4599.13059402 clock:7394.23082299999987\n",
      "Step:38300 batch_step:32 accuracy:0.98000002 full_accuracy:0.94017315 loss:43264.15155029 time:4611.17312407 clock:7413.58054199999970\n",
      "Step:38400 batch_step:32 accuracy:0.94000000 full_accuracy:0.93360960 loss:35775.78936768 time:4623.20515299 clock:7432.95302999999967\n",
      "Step:38500 batch_step:32 accuracy:0.96000004 full_accuracy:0.93806070 loss:28959.76511002 time:4635.26063395 clock:7452.31061499999942\n",
      "Step:38600 batch_step:32 accuracy:0.95999998 full_accuracy:0.93753254 loss:16254.07100010 time:4647.28272295 clock:7471.66075999999975\n",
      "Step:38700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94062573 loss:11090.82826424 time:4659.31497002 clock:7490.99602400000003\n",
      "Step:38800 batch_step:32 accuracy:0.96000004 full_accuracy:0.93662733 loss:12403.93180275 time:4671.35704207 clock:7510.38320699999986\n",
      "Step:38900 batch_step:32 accuracy:0.98000002 full_accuracy:0.93715531 loss:25526.66953468 time:4683.39649510 clock:7529.75322899999992\n",
      "Step:39000 batch_step:32 accuracy:0.97000003 full_accuracy:0.94364345 loss:10635.17753077 time:4695.42814493 clock:7549.10282999999981\n",
      "Step:39100 batch_step:32 accuracy:0.96000004 full_accuracy:0.94055033 loss:21597.56927490 time:4707.47213507 clock:7568.45954900000015\n",
      "Step:39200 batch_step:32 accuracy:0.96000004 full_accuracy:0.93881518 loss:13286.48331928 time:4719.50641990 clock:7587.82794699999977\n",
      "Step:39300 batch_step:32 accuracy:0.96000004 full_accuracy:0.94175744 loss:10175.30800389 time:4731.53615093 clock:7607.21889199999987\n",
      "Step:39400 batch_step:32 accuracy:0.96000004 full_accuracy:0.93542016 loss:19985.00260150 time:4743.58563900 clock:7626.57362099999955\n",
      "Step:39500 batch_step:32 accuracy:1.00000000 full_accuracy:0.94017315 loss:43937.71075439 time:4755.62514710 clock:7645.93379099999947\n",
      "Step:39600 batch_step:32 accuracy:0.99000001 full_accuracy:0.93821162 loss:15268.28474903 time:4767.66020298 clock:7665.31640199999947\n",
      "Step:39700 batch_step:32 accuracy:0.99000001 full_accuracy:0.93534470 loss:24829.93972111 time:4779.74706793 clock:7684.67608899999959\n",
      "Step:39800 batch_step:32 accuracy:0.95000005 full_accuracy:0.93006372 loss:25958.59684515 time:4791.78808689 clock:7704.06601499999942\n",
      "Step:39900 batch_step:32 accuracy:0.90000004 full_accuracy:0.93617469 loss:22606.86668587 time:4803.80521607 clock:7723.42566100000022\n",
      "Step:40000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94311541 loss:12622.51819611 time:4815.83208609 clock:7742.78404700000010\n",
      "Step:40100 batch_step:32 accuracy:0.93000007 full_accuracy:0.92606527 loss:19737.57590866 time:4827.94763303 clock:7762.16021999999975\n",
      "Step:40200 batch_step:32 accuracy:0.99000001 full_accuracy:0.93896598 loss:30979.17573929 time:4839.97070599 clock:7781.52449499999966\n",
      "Step:40300 batch_step:32 accuracy:0.97000003 full_accuracy:0.94122934 loss:15151.86792994 time:4851.98415208 clock:7800.88011999999981\n",
      "Step:40400 batch_step:32 accuracy:0.98999995 full_accuracy:0.93926781 loss:14678.77434349 time:4864.02994895 clock:7820.26489599999968\n",
      "Step:40500 batch_step:32 accuracy:0.93000001 full_accuracy:0.92946017 loss:30837.12819672 time:4876.04903388 clock:7839.61130099999991\n",
      "Step:40600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94613308 loss:4188.12531650 time:4888.04467702 clock:7858.94997700000022\n",
      "Step:40700 batch_step:32 accuracy:0.92000002 full_accuracy:0.93738174 loss:28293.15325046 time:4900.06030202 clock:7878.29478699999981\n",
      "Step:40800 batch_step:32 accuracy:0.93000001 full_accuracy:0.93066728 loss:24780.38599586 time:4912.08347702 clock:7897.66697699999986\n",
      "Step:40900 batch_step:32 accuracy:0.93000007 full_accuracy:0.93111992 loss:12665.51579475 time:4924.12005305 clock:7917.03562400000010\n",
      "Step:41000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94107842 loss:22185.13248444 time:4936.16292310 clock:7936.39144200000010\n",
      "Step:41100 batch_step:32 accuracy:0.97000003 full_accuracy:0.94055033 loss:12730.55511761 time:4948.17883897 clock:7955.73042699999951\n",
      "Step:41200 batch_step:32 accuracy:0.98000002 full_accuracy:0.94168204 loss:11025.64502144 time:4960.19139409 clock:7975.08013200000005\n",
      "Step:41300 batch_step:32 accuracy:0.88000000 full_accuracy:0.92644250 loss:24466.59177017 time:4972.22175503 clock:7994.47206300000016\n",
      "Step:41400 batch_step:32 accuracy:0.98000002 full_accuracy:0.94039941 loss:22339.99542046 time:4984.22332788 clock:8013.82432100000005\n",
      "Step:41500 batch_step:32 accuracy:0.92000002 full_accuracy:0.94047487 loss:29468.03636551 time:4996.25042796 clock:8033.19045800000004\n",
      "Step:41600 batch_step:32 accuracy:0.93000007 full_accuracy:0.93557119 loss:16142.12720108 time:5008.35383105 clock:8052.59774099999959\n",
      "Step:41700 batch_step:32 accuracy:0.95999998 full_accuracy:0.92681962 loss:13278.25816345 time:5020.38777900 clock:8071.96864399999959\n",
      "Step:41800 batch_step:32 accuracy:0.96000004 full_accuracy:0.94817007 loss:20050.08514071 time:5032.40667892 clock:8091.33328100000017\n",
      "Step:41900 batch_step:32 accuracy:0.99000001 full_accuracy:0.94273818 loss:7397.25470304 time:5044.43196607 clock:8110.69462899999962\n",
      "Step:42000 batch_step:32 accuracy:0.98000002 full_accuracy:0.93308145 loss:26335.13771820 time:5056.50898504 clock:8130.07718000000023\n",
      "Step:42100 batch_step:32 accuracy:0.96000004 full_accuracy:0.93202525 loss:37937.82632750 time:5068.52939892 clock:8149.45038399999976\n",
      "Step:42200 batch_step:32 accuracy:0.99000001 full_accuracy:0.94462419 loss:2804.37882879 time:5080.54149199 clock:8168.80477999999948\n",
      "Step:42300 batch_step:32 accuracy:0.97000003 full_accuracy:0.94055033 loss:20615.89801407 time:5092.56436491 clock:8188.20311899999979\n",
      "Step:42400 batch_step:32 accuracy:1.00000000 full_accuracy:0.93617457 loss:15695.32562828 time:5104.64749098 clock:8207.59826500000054\n",
      "Step:42500 batch_step:32 accuracy:0.98000002 full_accuracy:0.94228554 loss:8668.79429722 time:5116.68709993 clock:8226.97412900000018\n",
      "Step:42600 batch_step:32 accuracy:0.98000002 full_accuracy:0.94379437 loss:12633.69788909 time:5128.71480489 clock:8246.33752600000116\n",
      "Step:42700 batch_step:32 accuracy:0.95000005 full_accuracy:0.93798524 loss:15341.93870735 time:5140.73549891 clock:8265.70846700000038\n",
      "Step:42800 batch_step:32 accuracy:0.94000006 full_accuracy:0.93896604 loss:17835.20718694 time:5152.81417799 clock:8285.10699300000124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:42900 batch_step:32 accuracy:0.99000001 full_accuracy:0.93994683 loss:18389.34783530 time:5164.83854699 clock:8304.48359200000050\n",
      "Step:43000 batch_step:32 accuracy:0.95000005 full_accuracy:0.92636704 loss:25869.90268707 time:5176.85587001 clock:8323.83725000000049\n",
      "Step:43100 batch_step:32 accuracy:0.99000001 full_accuracy:0.94424707 loss:12853.50850534 time:5188.88949490 clock:8343.20392100000026\n",
      "Step:43200 batch_step:32 accuracy:0.99000001 full_accuracy:0.93557107 loss:31817.26711130 time:5200.90058899 clock:8362.57671500000106\n",
      "Step:43300 batch_step:32 accuracy:0.98000002 full_accuracy:0.94364351 loss:22250.24514675 time:5212.93191791 clock:8381.93166900000142\n",
      "Step:43400 batch_step:32 accuracy:0.98000002 full_accuracy:0.93813616 loss:12161.80239987 time:5224.98335910 clock:8401.29755600000135\n",
      "Step:43500 batch_step:32 accuracy:1.00000000 full_accuracy:0.94341719 loss:13714.05507851 time:5237.01218605 clock:8420.65419600000132\n",
      "Step:43600 batch_step:32 accuracy:0.99000001 full_accuracy:0.94107842 loss:18564.13472986 time:5249.02957892 clock:8440.01232500000151\n",
      "Step:43700 batch_step:32 accuracy:0.97000003 full_accuracy:0.93707997 loss:27167.64236069 time:5261.07327199 clock:8459.38910399999986\n",
      "Step:43800 batch_step:32 accuracy:0.97000003 full_accuracy:0.93715543 loss:9840.31647155 time:5273.10431504 clock:8478.76344000000063\n",
      "Step:43900 batch_step:32 accuracy:0.98000002 full_accuracy:0.92568803 loss:47554.34391499 time:5285.13259292 clock:8498.13602900000114\n",
      "Step:44000 batch_step:32 accuracy:0.97000003 full_accuracy:0.94583130 loss:5709.47250453 time:5297.17840600 clock:8517.51100000000042\n",
      "Step:44100 batch_step:32 accuracy:0.98000002 full_accuracy:0.93904150 loss:36297.73342133 time:5309.20643806 clock:8536.87292700000035\n",
      "Step:44200 batch_step:32 accuracy:0.97000003 full_accuracy:0.94500148 loss:13208.07096100 time:5321.23835206 clock:8556.24776999999995\n",
      "Step:44300 batch_step:32 accuracy:0.96000004 full_accuracy:0.94122934 loss:8344.69678569 time:5333.27176905 clock:8575.60605500000020\n",
      "Step:44400 batch_step:32 accuracy:0.99000001 full_accuracy:0.94386989 loss:21365.78678894 time:5345.31368399 clock:8594.98317600000155\n",
      "Step:44500 batch_step:32 accuracy:0.98000002 full_accuracy:0.94145560 loss:6766.49033928 time:5357.34464693 clock:8614.36448100000052\n",
      "Step:44600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94122934 loss:23191.94469023 time:5369.37099290 clock:8633.71570400000019\n",
      "Step:44700 batch_step:32 accuracy:0.98000002 full_accuracy:0.94175738 loss:12419.86147308 time:5381.41974902 clock:8653.07543000000078\n",
      "Step:44800 batch_step:32 accuracy:0.95999998 full_accuracy:0.93436390 loss:21611.52097106 time:5393.47062397 clock:8672.45938900000147\n",
      "Step:44900 batch_step:32 accuracy:0.98000002 full_accuracy:0.94771743 loss:11111.05239391 time:5405.51237798 clock:8691.82038600000124\n",
      "Step:45000 batch_step:32 accuracy:0.97000003 full_accuracy:0.94568050 loss:29121.97852707 time:5417.56029010 clock:8711.20075400000133\n",
      "Step:45100 batch_step:32 accuracy:0.98000002 full_accuracy:0.94432253 loss:11109.07699394 time:5429.58916402 clock:8730.56908600000133\n",
      "Step:45200 batch_step:32 accuracy:0.98999995 full_accuracy:0.94303995 loss:10472.48515224 time:5441.64632702 clock:8749.93869400000040\n",
      "Step:45300 batch_step:32 accuracy:0.97000003 full_accuracy:0.93119538 loss:45949.39257050 time:5453.66857696 clock:8769.30705000000125\n",
      "Step:45400 batch_step:32 accuracy:0.97000003 full_accuracy:0.94213468 loss:21150.60371399 time:5465.69690800 clock:8788.68261200000052\n",
      "Step:45500 batch_step:32 accuracy:0.97000003 full_accuracy:0.92991292 loss:19135.13372803 time:5477.74786210 clock:8808.04926300000079\n",
      "Step:45600 batch_step:32 accuracy:0.99000001 full_accuracy:0.93217623 loss:11202.14029217 time:5489.78121901 clock:8827.40213100000074\n",
      "Step:45700 batch_step:32 accuracy:0.97000003 full_accuracy:0.93926787 loss:27485.00071526 time:5501.81832504 clock:8846.78986500000065\n",
      "Step:45800 batch_step:32 accuracy:0.97000003 full_accuracy:0.94394535 loss:6988.93121672 time:5513.84564805 clock:8866.16471200000160\n",
      "Step:45900 batch_step:32 accuracy:0.95000005 full_accuracy:0.93813616 loss:20412.27629042 time:5525.88800311 clock:8885.53397200000109\n",
      "Step:46000 batch_step:32 accuracy:0.94000006 full_accuracy:0.93715537 loss:15266.03879756 time:5537.94110489 clock:8904.91053500000089\n",
      "Step:46100 batch_step:32 accuracy:1.00000000 full_accuracy:0.94522780 loss:11646.92798042 time:5549.98970604 clock:8924.31756200000018\n",
      "Step:46200 batch_step:32 accuracy:0.99000001 full_accuracy:0.94779289 loss:10564.13321632 time:5562.03024411 clock:8943.66951400000107\n",
      "Step:46300 batch_step:32 accuracy:0.99000001 full_accuracy:0.94613320 loss:1269.73689032 time:5574.06638002 clock:8963.04414100000031\n",
      "Step:46400 batch_step:32 accuracy:0.97999996 full_accuracy:0.94122934 loss:13146.96944237 time:5586.11989093 clock:8982.41826700000092\n",
      "Step:46500 batch_step:32 accuracy:0.99000001 full_accuracy:0.94711381 loss:1545.96576093 time:5598.17393303 clock:9001.80475300000035\n",
      "Step:46600 batch_step:32 accuracy:0.96999997 full_accuracy:0.93262875 loss:28676.90037203 time:5610.20120907 clock:9021.19170500000109\n",
      "Step:46700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94560504 loss:3765.15483665 time:5622.22430301 clock:9040.54681300000084\n",
      "Step:46800 batch_step:32 accuracy:0.96000004 full_accuracy:0.93745720 loss:23168.80837965 time:5634.28454590 clock:9059.92637600000126\n",
      "Step:46900 batch_step:32 accuracy:0.97000003 full_accuracy:0.94273818 loss:11360.51603317 time:5646.32052302 clock:9079.29583900000034\n",
      "Step:47000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94311535 loss:7964.26139164 time:5658.34216690 clock:9098.65356600000086\n",
      "Step:47100 batch_step:32 accuracy:0.96000004 full_accuracy:0.94537866 loss:4189.84164369 time:5670.37198591 clock:9118.04948900000090\n",
      "Step:47200 batch_step:32 accuracy:0.98000002 full_accuracy:0.94605768 loss:4561.93018675 time:5682.41580200 clock:9137.41831000000093\n",
      "Step:47300 batch_step:32 accuracy:0.99000001 full_accuracy:0.94462425 loss:1190.75311869 time:5694.46851110 clock:9156.79940200000055\n",
      "Step:47400 batch_step:32 accuracy:0.99000001 full_accuracy:0.94092751 loss:39469.62726593 time:5706.50345707 clock:9176.14769900000101\n",
      "Step:47500 batch_step:32 accuracy:0.97000003 full_accuracy:0.94002223 loss:7301.57001150 time:5718.53069997 clock:9195.50524300000143\n",
      "Step:47600 batch_step:32 accuracy:0.99000001 full_accuracy:0.94696307 loss:6371.00293732 time:5730.55355501 clock:9214.87885000000097\n",
      "Step:47700 batch_step:32 accuracy:0.95000005 full_accuracy:0.94092751 loss:27400.51338196 time:5742.58894610 clock:9234.27811300000030\n",
      "Step:47800 batch_step:32 accuracy:0.98000002 full_accuracy:0.93904138 loss:9888.67584252 time:5754.63890696 clock:9253.65727300000071\n",
      "Step:47900 batch_step:32 accuracy:0.99000001 full_accuracy:0.94319087 loss:8584.89851189 time:5766.68249393 clock:9273.02301600000101\n",
      "Step:48000 batch_step:32 accuracy:0.96000004 full_accuracy:0.94417161 loss:17039.57969666 time:5778.73878598 clock:9292.38979800000016\n",
      "Step:48100 batch_step:32 accuracy:0.97999996 full_accuracy:0.94017309 loss:37215.05941391 time:5790.76907706 clock:9311.73720400000093\n",
      "Step:48200 batch_step:32 accuracy:0.98000002 full_accuracy:0.94771743 loss:11137.30533171 time:5802.80815506 clock:9331.09805000000051\n",
      "Step:48300 batch_step:32 accuracy:0.93000001 full_accuracy:0.94153106 loss:15710.08559489 time:5814.85122204 clock:9350.46843200000148\n",
      "Step:48400 batch_step:32 accuracy:0.96000004 full_accuracy:0.93647641 loss:20352.43010908 time:5826.90310693 clock:9369.80483500000082\n",
      "Step:48500 batch_step:32 accuracy:0.96999997 full_accuracy:0.94070125 loss:10467.84494495 time:5838.94481206 clock:9389.16113700000096\n",
      "Step:48600 batch_step:32 accuracy:0.93000007 full_accuracy:0.93632555 loss:10905.51423247 time:5850.98005891 clock:9408.53967300000113\n",
      "Step:48700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94749111 loss:4386.82117081 time:5863.02649903 clock:9427.92292600000110\n",
      "Step:48800 batch_step:32 accuracy:1.00000000 full_accuracy:0.94522786 loss:2438.99038804 time:5875.05717206 clock:9447.29103900000155\n",
      "Step:48900 batch_step:32 accuracy:0.95000005 full_accuracy:0.94575590 loss:9969.10656548 time:5887.09433508 clock:9466.64590200000021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:49000 batch_step:32 accuracy:0.99000001 full_accuracy:0.94688755 loss:7040.48805761 time:5899.13257194 clock:9486.04480599999988\n",
      "Step:49100 batch_step:32 accuracy:0.99000001 full_accuracy:0.94311535 loss:6112.72196960 time:5911.16186094 clock:9505.41626800000085\n",
      "Step:49200 batch_step:32 accuracy:0.96000004 full_accuracy:0.94115382 loss:32794.97224426 time:5923.21826601 clock:9524.80573100000038\n",
      "Step:49300 batch_step:32 accuracy:1.00000000 full_accuracy:0.94681215 loss:4986.31568396 time:5935.26914811 clock:9544.17672300000049\n",
      "Step:49400 batch_step:32 accuracy:0.97999996 full_accuracy:0.94236100 loss:22576.57012749 time:5947.31133509 clock:9563.57467700000052\n",
      "Step:49500 batch_step:32 accuracy:0.98000002 full_accuracy:0.94047493 loss:13845.47753286 time:5959.35110497 clock:9582.94417900000008\n",
      "Step:49600 batch_step:32 accuracy:0.98999995 full_accuracy:0.94311541 loss:6843.76274443 time:5971.37784195 clock:9602.31292900000153\n",
      "Step:49700 batch_step:32 accuracy:0.98000002 full_accuracy:0.94598222 loss:5014.43902111 time:5983.43283296 clock:9621.68917300000066\n",
      "Step:49800 batch_step:32 accuracy:1.00000000 full_accuracy:0.94552958 loss:6698.39546800 time:5995.48315191 clock:9641.08332000000155\n",
      "Step:49900 batch_step:32 accuracy:1.00000000 full_accuracy:0.94424707 loss:9047.57516742 time:6007.52480006 clock:9660.41829500000131\n",
      "Step:50000 batch_step:32 accuracy:0.97000003 full_accuracy:0.94402069 loss:10568.21101189 time:6019.55949306 clock:9679.78385700000035\n",
      "Step:50100 batch_step:32 accuracy:0.97000003 full_accuracy:0.94205922 loss:14415.58620262 time:6031.61526108 clock:9699.16876600000069\n",
      "Step:50200 batch_step:32 accuracy:0.95000005 full_accuracy:0.94900000 loss:5998.11316013 time:6043.66351604 clock:9718.53796100000000\n",
      "Step:50300 batch_step:32 accuracy:1.00000000 full_accuracy:0.94741565 loss:341.78998804 time:6055.72263908 clock:9737.88583500000095\n",
      "Step:50400 batch_step:32 accuracy:0.97000003 full_accuracy:0.94530332 loss:9474.25363541 time:6067.76517892 clock:9757.24618800000098\n",
      "Step:50500 batch_step:32 accuracy:0.97000003 full_accuracy:0.94485062 loss:6334.15526962 time:6079.78630495 clock:9776.59889800000019\n",
      "Step:50600 batch_step:32 accuracy:0.98000002 full_accuracy:0.94039947 loss:15446.37909317 time:6091.82408690 clock:9795.97469900000033\n",
      "Step:50700 batch_step:32 accuracy:0.97000003 full_accuracy:0.94432247 loss:8260.51073837 time:6103.86502504 clock:9815.37275700000100\n",
      "Step:50800 batch_step:32 accuracy:1.00000000 full_accuracy:0.94537872 loss:4886.20831394 time:6115.91215491 clock:9834.72657500000059\n",
      "Step:50900 batch_step:32 accuracy:0.97999996 full_accuracy:0.93074274 loss:57436.28738403 time:6127.95535588 clock:9854.08259100000032\n",
      "Step:51000 batch_step:32 accuracy:0.98000002 full_accuracy:0.94198376 loss:32104.77470398 time:6139.99677992 clock:9873.44229300000006\n",
      "Step:51100 batch_step:32 accuracy:0.97000003 full_accuracy:0.94635946 loss:4994.62153149 time:6152.04537892 clock:9892.80763400000069\n",
      "Step:51200 batch_step:32 accuracy:0.94999999 full_accuracy:0.94500148 loss:6207.61848068 time:6164.09396911 clock:9912.17782799999986\n",
      "Step:51300 batch_step:32 accuracy:0.97000003 full_accuracy:0.94515240 loss:8254.04794216 time:6176.13578510 clock:9931.55032200000096\n",
      "Step:51400 batch_step:32 accuracy:0.98000002 full_accuracy:0.94266272 loss:18667.31827956 time:6188.17869902 clock:9950.87834199999998\n",
      "Step:51500 batch_step:32 accuracy:0.99000001 full_accuracy:0.94794375 loss:3975.43469334 time:6200.21076989 clock:9970.21550999999999\n",
      "Step:51600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94379437 loss:4538.13821721 time:6212.24605298 clock:9989.61013400000047\n",
      "Step:51700 batch_step:32 accuracy:0.99000001 full_accuracy:0.94515240 loss:57313.38057709 time:6224.31536603 clock:10009.02038800000082\n",
      "Step:51800 batch_step:32 accuracy:0.97000003 full_accuracy:0.94409609 loss:5413.91699219 time:6236.36978388 clock:10028.35805799999980\n",
      "Step:51900 batch_step:32 accuracy:0.98000002 full_accuracy:0.94530326 loss:4919.14417839 time:6248.42328191 clock:10047.72655400000076\n",
      "Step:52000 batch_step:32 accuracy:0.96000004 full_accuracy:0.93489206 loss:14655.16509914 time:6260.46909189 clock:10067.09912900000018\n",
      "Step:52100 batch_step:32 accuracy:0.99000001 full_accuracy:0.94990528 loss:2701.04697180 time:6272.50936508 clock:10086.45005000000128\n",
      "Step:52200 batch_step:32 accuracy:0.99000001 full_accuracy:0.94454879 loss:14052.48241901 time:6284.56960797 clock:10105.83583900000122\n",
      "Step:52300 batch_step:32 accuracy:0.99000001 full_accuracy:0.94379443 loss:9812.04648733 time:6296.63550901 clock:10125.21671100000094\n",
      "Step:52400 batch_step:32 accuracy:0.99000001 full_accuracy:0.94726473 loss:1650.98964286 time:6308.68235087 clock:10144.54684100000122\n",
      "Step:52500 batch_step:32 accuracy:0.96000004 full_accuracy:0.94213462 loss:19348.74905777 time:6320.71895695 clock:10163.92489100000057\n",
      "Step:52600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94824553 loss:12912.83865738 time:6332.75237608 clock:10183.26617799999985\n",
      "Step:52700 batch_step:32 accuracy:0.95999998 full_accuracy:0.94477510 loss:9017.17408752 time:6344.80254793 clock:10202.64292400000159\n",
      "Step:52800 batch_step:32 accuracy:1.00000000 full_accuracy:0.94862270 loss:3865.95996571 time:6356.85998487 clock:10222.01614000000154\n",
      "Step:52900 batch_step:32 accuracy:0.98000002 full_accuracy:0.93941867 loss:9639.75318933 time:6368.89816308 clock:10241.36694600000010\n",
      "Step:53000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94515228 loss:8508.89560032 time:6380.95024204 clock:10260.75408200000129\n",
      "Step:53100 batch_step:32 accuracy:1.00000000 full_accuracy:0.94900000 loss:3453.88685894 time:6392.98135805 clock:10280.12529499999982\n",
      "Step:53200 batch_step:32 accuracy:0.98000002 full_accuracy:0.94734025 loss:8596.38540268 time:6405.02393603 clock:10299.49083600000085\n",
      "Step:53300 batch_step:32 accuracy:0.98000002 full_accuracy:0.94718933 loss:1909.31863332 time:6417.06443405 clock:10318.85682600000109\n",
      "Step:53400 batch_step:32 accuracy:1.00000000 full_accuracy:0.94915080 loss:5830.71883392 time:6429.10451698 clock:10338.20624500000122\n",
      "Step:53500 batch_step:32 accuracy:0.99000001 full_accuracy:0.93956965 loss:17681.18906403 time:6441.15165901 clock:10357.54874300000120\n",
      "Step:53600 batch_step:32 accuracy:0.99000001 full_accuracy:0.94673663 loss:4351.25110245 time:6453.21328092 clock:10376.94545800000014\n",
      "Step:53700 batch_step:32 accuracy:0.95999998 full_accuracy:0.94047487 loss:6931.80068970 time:6465.27683592 clock:10396.30790400000114\n",
      "Step:53800 batch_step:32 accuracy:0.99000001 full_accuracy:0.94319093 loss:18456.88974571 time:6477.32303810 clock:10415.71929100000125\n",
      "Step:53900 batch_step:32 accuracy:1.00000000 full_accuracy:0.94213462 loss:10252.27749252 time:6489.37117290 clock:10435.09910800000034\n",
      "Step:54000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95013154 loss:1766.00151730 time:6501.42592311 clock:10454.47967600000084\n",
      "Step:54100 batch_step:32 accuracy:0.99000001 full_accuracy:0.94598228 loss:6222.17432788 time:6514.16679311 clock:10473.94378300000062\n",
      "Step:54200 batch_step:32 accuracy:0.99000001 full_accuracy:0.94334173 loss:5392.34291410 time:6526.41835999 clock:10493.31077400000140\n",
      "Step:54300 batch_step:32 accuracy:0.97000003 full_accuracy:0.94537866 loss:9579.06887245 time:6538.92196608 clock:10512.73294900000110\n",
      "Step:54400 batch_step:32 accuracy:1.00000000 full_accuracy:0.94824553 loss:4036.52231038 time:6550.98151207 clock:10532.13347500000054\n",
      "Step:54500 batch_step:32 accuracy:1.00000000 full_accuracy:0.94681209 loss:25155.09897661 time:6563.02954888 clock:10551.51497800000107\n",
      "Step:54600 batch_step:32 accuracy:0.97000003 full_accuracy:0.93813610 loss:34103.45913696 time:6575.08471203 clock:10570.91446800000085\n",
      "Step:54700 batch_step:32 accuracy:1.00000000 full_accuracy:0.94801921 loss:3773.13065004 time:6587.14663005 clock:10590.30914500000108\n",
      "Step:54800 batch_step:32 accuracy:0.99000001 full_accuracy:0.94801921 loss:1666.47392723 time:6599.19935799 clock:10609.72484700000132\n",
      "Step:54900 batch_step:32 accuracy:0.97000003 full_accuracy:0.94462430 loss:6059.72142327 time:6611.23819590 clock:10629.08666700000140\n",
      "Step:55000 batch_step:32 accuracy:0.99000001 full_accuracy:0.94666117 loss:15053.67461395 time:6623.28160691 clock:10648.43915999999990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:55100 batch_step:32 accuracy:0.98000002 full_accuracy:0.94839644 loss:1969.85178041 time:6635.33647799 clock:10667.81856500000140\n",
      "Step:55200 batch_step:32 accuracy:1.00000000 full_accuracy:0.94764197 loss:1346.22523880 time:6647.38206410 clock:10687.16991200000120\n",
      "Step:55300 batch_step:32 accuracy:0.96000004 full_accuracy:0.94598222 loss:14268.48005676 time:6659.42617106 clock:10706.52309100000093\n",
      "Step:55400 batch_step:32 accuracy:0.94000006 full_accuracy:0.93896604 loss:23004.81458855 time:6671.46777701 clock:10725.90221700000075\n",
      "Step:55500 batch_step:32 accuracy:0.98000002 full_accuracy:0.93293053 loss:5874.59376287 time:6683.50787997 clock:10745.25609600000098\n",
      "Step:55600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94688749 loss:5925.70840836 time:6695.54845500 clock:10764.63064200000008\n",
      "Step:55700 batch_step:32 accuracy:0.97000003 full_accuracy:0.93745714 loss:21010.97374725 time:6707.57825303 clock:10783.97409300000072\n",
      "Step:55800 batch_step:32 accuracy:0.98000002 full_accuracy:0.94447339 loss:3251.88879108 time:6719.74195695 clock:10803.31771500000104\n",
      "Step:55900 batch_step:32 accuracy:1.00000000 full_accuracy:0.94552958 loss:9942.32147670 time:6732.70935392 clock:10822.76240000000143\n",
      "Step:56000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94643492 loss:4087.80959058 time:6745.61236691 clock:10842.31089100000099\n",
      "Step:56100 batch_step:32 accuracy:1.00000000 full_accuracy:0.94515234 loss:4463.43451309 time:6758.31134009 clock:10861.78455399999984\n",
      "Step:56200 batch_step:32 accuracy:0.96000004 full_accuracy:0.94070125 loss:3305.19862175 time:6770.62296295 clock:10881.20440100000087\n",
      "Step:56300 batch_step:32 accuracy:1.00000000 full_accuracy:0.94432247 loss:12275.60671461 time:6782.68458796 clock:10900.55169700000079\n",
      "Step:56400 batch_step:32 accuracy:0.99000001 full_accuracy:0.94469976 loss:1313.53915882 time:6794.72850800 clock:10919.92596400000002\n",
      "Step:56500 batch_step:32 accuracy:1.00000000 full_accuracy:0.94469965 loss:9347.37396669 time:6806.79916596 clock:10939.29682200000025\n",
      "Step:56600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94786829 loss:3079.90366375 time:6818.84799910 clock:10958.66147799999999\n",
      "Step:56700 batch_step:32 accuracy:0.97000003 full_accuracy:0.94681215 loss:6825.99017525 time:6830.89856696 clock:10978.03745700000036\n",
      "Step:56800 batch_step:32 accuracy:1.00000000 full_accuracy:0.93987131 loss:4482.87781620 time:6842.95612407 clock:10997.42202400000133\n",
      "Step:56900 batch_step:32 accuracy:0.99000001 full_accuracy:0.94560504 loss:8042.37225628 time:6854.99444389 clock:11016.76294200000120\n",
      "Step:57000 batch_step:32 accuracy:0.98000002 full_accuracy:0.94477510 loss:20044.65401459 time:6867.04543996 clock:11036.09710000000086\n",
      "Step:57100 batch_step:32 accuracy:0.99000001 full_accuracy:0.94153112 loss:11966.77153079 time:6879.07854891 clock:11055.45880200000101\n",
      "Step:57200 batch_step:32 accuracy:0.96000004 full_accuracy:0.94024855 loss:18028.69080162 time:6891.19226003 clock:11074.91536799999994\n",
      "Step:57300 batch_step:32 accuracy:1.00000000 full_accuracy:0.94205916 loss:19294.45592880 time:6903.24161196 clock:11094.28502300000036\n",
      "Step:57400 batch_step:32 accuracy:0.99000001 full_accuracy:0.94666123 loss:11509.45511949 time:6915.29452610 clock:11113.61301500000081\n",
      "Step:57500 batch_step:32 accuracy:0.94000006 full_accuracy:0.94341713 loss:5620.79772019 time:6927.32855105 clock:11132.94885400000021\n",
      "Step:57600 batch_step:32 accuracy:0.97000003 full_accuracy:0.94175744 loss:26867.74337387 time:6939.38169599 clock:11152.33692400000109\n",
      "Step:57700 batch_step:32 accuracy:0.98000002 full_accuracy:0.94213468 loss:7400.09408951 time:6951.44193292 clock:11171.68025000000125\n",
      "Step:57800 batch_step:32 accuracy:0.99000001 full_accuracy:0.94281363 loss:10275.08407038 time:6963.50029707 clock:11191.02789200000007\n",
      "Step:57900 batch_step:32 accuracy:1.00000000 full_accuracy:0.94877368 loss:4157.60869050 time:6975.56162596 clock:11210.37292900000102\n",
      "Step:58000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95005620 loss:3463.42802382 time:6987.61400890 clock:11229.73202099999980\n",
      "Step:58100 batch_step:32 accuracy:1.00000000 full_accuracy:0.94605762 loss:2112.85517895 time:6999.66190791 clock:11249.08575500000006\n",
      "Step:58200 batch_step:32 accuracy:0.99000001 full_accuracy:0.94605768 loss:2547.40077549 time:7011.72624397 clock:11268.45028500000080\n",
      "Step:58300 batch_step:32 accuracy:0.96000004 full_accuracy:0.94221008 loss:6276.19278431 time:7023.99551988 clock:11287.80375199999980\n",
      "Step:58400 batch_step:32 accuracy:1.00000000 full_accuracy:0.94651037 loss:1135.41195488 time:7036.77577996 clock:11307.30193500000132\n",
      "Step:58500 batch_step:32 accuracy:0.97000003 full_accuracy:0.94002223 loss:18213.45051956 time:7049.68485498 clock:11326.74944800000048\n",
      "Step:58600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94786835 loss:763.54908514 time:7062.53177595 clock:11346.21127400000114\n",
      "Step:58700 batch_step:32 accuracy:0.99000001 full_accuracy:0.95005620 loss:3039.72565198 time:7075.38863802 clock:11365.75946400000066\n",
      "Step:58800 batch_step:32 accuracy:0.98000002 full_accuracy:0.93843794 loss:18846.21607018 time:7087.42641497 clock:11385.11111600000004\n",
      "Step:58900 batch_step:32 accuracy:0.99000001 full_accuracy:0.94613314 loss:939.26201034 time:7099.47298002 clock:11404.46023100000093\n",
      "Step:59000 batch_step:32 accuracy:1.00000000 full_accuracy:0.94266272 loss:5132.44731140 time:7111.51030087 clock:11423.81240299999990\n",
      "Step:59100 batch_step:32 accuracy:0.97000003 full_accuracy:0.94500136 loss:12901.81653690 time:7123.56733298 clock:11443.18166900000142\n",
      "Step:59200 batch_step:32 accuracy:0.96000004 full_accuracy:0.94009769 loss:6606.59430814 time:7135.61475801 clock:11462.54635100000087\n",
      "Step:59300 batch_step:32 accuracy:0.99000001 full_accuracy:0.94945270 loss:4297.67589211 time:7148.00692201 clock:11482.01679599999989\n",
      "Step:59400 batch_step:32 accuracy:0.99000001 full_accuracy:0.94741571 loss:2251.26731360 time:7160.27089500 clock:11501.48988400000053\n",
      "Step:59500 batch_step:32 accuracy:1.00000000 full_accuracy:0.94726479 loss:5258.14505196 time:7172.84417009 clock:11520.89415900000131\n",
      "Step:59600 batch_step:32 accuracy:1.00000000 full_accuracy:0.94915092 loss:3824.41242194 time:7184.91125202 clock:11540.26882800000021\n",
      "Step:59700 batch_step:32 accuracy:0.98000002 full_accuracy:0.94492596 loss:7962.52408886 time:7196.95935202 clock:11559.66002900000058\n",
      "Step:59800 batch_step:32 accuracy:0.99000001 full_accuracy:0.94764197 loss:8401.77458623 time:7209.01660299 clock:11579.05658000000039\n",
      "Step:59900 batch_step:32 accuracy:1.00000000 full_accuracy:0.94824553 loss:2344.64698410 time:7221.06007910 clock:11598.42293200000131\n",
      "Step:60000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7233.11182690 clock:11617.79359400000067\n",
      "Step:60100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7245.11481309 clock:11637.13303799999994\n",
      "Step:60200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7257.11152005 clock:11656.41174700000010\n",
      "Step:60300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7269.10464001 clock:11675.72639700000036\n",
      "Step:60400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7281.10601401 clock:11695.02417600000081\n",
      "Step:60500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7293.09390688 clock:11714.35326600000008\n",
      "Step:60600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7305.10373497 clock:11733.67023900000095\n",
      "Step:60700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7317.11412406 clock:11752.97852700000112\n",
      "Step:60800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7329.12596607 clock:11772.31322700000055\n",
      "Step:60900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7341.15445399 clock:11791.58952300000055\n",
      "Step:61000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7353.16497803 clock:11810.91250700000091\n",
      "Step:61100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7365.18510389 clock:11830.24816000000101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:61200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7377.19239593 clock:11849.57769800000096\n",
      "Step:61300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7389.22536898 clock:11868.91360600000007\n",
      "Step:61400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7401.24603009 clock:11888.24438100000043\n",
      "Step:61500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7413.27874303 clock:11907.54401700000017\n",
      "Step:61600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7425.29009390 clock:11926.88864100000137\n",
      "Step:61700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7437.32513189 clock:11946.23383800000011\n",
      "Step:61800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7449.35529304 clock:11965.58483700000033\n",
      "Step:61900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7461.42378592 clock:11984.95744300000115\n",
      "Step:62000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7473.47852898 clock:12004.31839300000138\n",
      "Step:62100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7485.55366302 clock:12023.69946400000117\n",
      "Step:62200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7497.61771202 clock:12043.06919700000071\n",
      "Step:62300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7509.68134904 clock:12062.40939900000012\n",
      "Step:62400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7521.73006892 clock:12081.76820200000111\n",
      "Step:62500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7533.76571608 clock:12101.12852600000042\n",
      "Step:62600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7545.83115792 clock:12120.52398800000083\n",
      "Step:62700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7557.85397911 clock:12139.87965100000110\n",
      "Step:62800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7569.88086700 clock:12159.22123600000123\n",
      "Step:62900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7581.90363789 clock:12178.53985500000090\n",
      "Step:63000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7593.90005207 clock:12197.85834800000157\n",
      "Step:63100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7605.90757704 clock:12217.20720100000108\n",
      "Step:63200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7617.90976906 clock:12236.50709300000017\n",
      "Step:63300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7629.90779209 clock:12255.81067600000097\n",
      "Step:63400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7641.89873004 clock:12275.12391500000012\n",
      "Step:63500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7653.90904808 clock:12294.43493600000147\n",
      "Step:63600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7665.90072393 clock:12313.76484600000003\n",
      "Step:63700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7677.89594603 clock:12333.08357800000158\n",
      "Step:63800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7689.90493393 clock:12352.40333500000088\n",
      "Step:63900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7701.92891407 clock:12371.73762100000022\n",
      "Step:64000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7713.93910789 clock:12391.05731100000048\n",
      "Step:64100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7725.93868303 clock:12410.38664800000151\n",
      "Step:64200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7737.94418502 clock:12429.71846600000026\n",
      "Step:64300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7749.91909695 clock:12449.05267000000094\n",
      "Step:64400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7761.92932391 clock:12468.37854500000140\n",
      "Step:64500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7773.91367102 clock:12487.69112099999984\n",
      "Step:64600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7785.96435905 clock:12507.06124100000125\n",
      "Step:64700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7797.97797108 clock:12526.37205200000062\n",
      "Step:64800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7809.95230293 clock:12545.66731500000060\n",
      "Step:64900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7821.95278192 clock:12564.98217699999987\n",
      "Step:65000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7833.95062304 clock:12584.29078800000025\n",
      "Step:65100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7845.95427299 clock:12603.62863000000107\n",
      "Step:65200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7857.98200607 clock:12622.98098300000129\n",
      "Step:65300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7869.99180508 clock:12642.29324700000143\n",
      "Step:65400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7881.98247695 clock:12661.62070900000072\n",
      "Step:65500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7893.98952889 clock:12680.94463300000098\n",
      "Step:65600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7905.99976301 clock:12700.28814300000158\n",
      "Step:65700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7918.02916789 clock:12719.60653000000093\n",
      "Step:65800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7930.04015493 clock:12738.91104300000006\n",
      "Step:65900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7942.03911996 clock:12758.19601800000055\n",
      "Step:66000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7954.04735208 clock:12777.51989300000059\n",
      "Step:66100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7966.04635596 clock:12796.85202200000094\n",
      "Step:66200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:7978.04801393 clock:12816.20537100000001\n",
      "Step:66300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:7990.04939890 clock:12835.52922000000035\n",
      "Step:66400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8002.05112410 clock:12854.86120900000060\n",
      "Step:66500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8014.05884695 clock:12874.20405900000151\n",
      "Step:66600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8026.07126307 clock:12893.52649300000121\n",
      "Step:66700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8038.07093596 clock:12912.82679900000039\n",
      "Step:66800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8050.06204891 clock:12932.13119000000006\n",
      "Step:66900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8062.08020806 clock:12951.41887200000019\n",
      "Step:67000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8074.06776905 clock:12970.74045300000034\n",
      "Step:67100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8086.06685996 clock:12990.05568400000084\n",
      "Step:67200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8098.07403588 clock:13009.37701100000049\n",
      "Step:67300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8110.06751990 clock:13028.66004500000054\n",
      "Step:67400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8122.06913996 clock:13047.94091200000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:67500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8134.07721400 clock:13067.25509200000124\n",
      "Step:67600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8146.07469606 clock:13086.55351500000143\n",
      "Step:67700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8158.07914400 clock:13105.86688900000081\n",
      "Step:67800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8170.06091499 clock:13125.14021600000160\n",
      "Step:67900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8182.04768991 clock:13144.42226800000026\n",
      "Step:68000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8194.02554202 clock:13163.72785000000113\n",
      "Step:68100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8206.00806189 clock:13183.00954300000012\n",
      "Step:68200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8218.01295710 clock:13202.31564800000160\n",
      "Step:68300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8229.97554398 clock:13221.62609100000009\n",
      "Step:68400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8241.95847106 clock:13240.92804000000069\n",
      "Step:68500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8253.92693305 clock:13260.22887700000138\n",
      "Step:68600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8265.94254208 clock:13279.56512600000133\n",
      "Step:68700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8277.93792796 clock:13298.89716300000146\n",
      "Step:68800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8289.93329811 clock:13318.20339700000113\n",
      "Step:68900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8301.91758704 clock:13337.48624999999993\n",
      "Step:69000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8313.91468811 clock:13356.79298000000017\n",
      "Step:69100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8325.89795995 clock:13376.09379100000115\n",
      "Step:69200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8337.87635589 clock:13395.38653100000010\n",
      "Step:69300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8349.85640287 clock:13414.71226000000024\n",
      "Step:69400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8361.82892108 clock:13434.01442700000007\n",
      "Step:69500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8373.82732987 clock:13453.31514800000150\n",
      "Step:69600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8385.83556795 clock:13472.65828300000067\n",
      "Step:69700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8397.85070801 clock:13491.98119399999996\n",
      "Step:69800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8409.84917307 clock:13511.30013300000064\n",
      "Step:69900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8421.83549690 clock:13530.62418700000126\n",
      "Step:70000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8433.83401299 clock:13549.97013000000152\n",
      "Step:70100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8445.81717896 clock:13569.28322400000070\n",
      "Step:70200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8457.79647207 clock:13588.58673900000031\n",
      "Step:70300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8469.93562603 clock:13607.89905400000134\n",
      "Step:70400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8481.91693211 clock:13627.19806000000062\n",
      "Step:70500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8493.89518595 clock:13646.46993900000052\n",
      "Step:70600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8505.87875700 clock:13665.77850500000022\n",
      "Step:70700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8517.86981511 clock:13685.09536800000024\n",
      "Step:70800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8529.85242295 clock:13704.38668400000097\n",
      "Step:70900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8541.84565806 clock:13723.70950900000025\n",
      "Step:71000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8553.81525707 clock:13743.01089400000092\n",
      "Step:71100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8565.79075599 clock:13762.30345900000066\n",
      "Step:71200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8577.79695106 clock:13781.61482000000069\n",
      "Step:71300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8589.82075810 clock:13800.92121800000132\n",
      "Step:71400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8601.80272794 clock:13820.23935400000119\n",
      "Step:71500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8613.77454996 clock:13839.53325700000096\n",
      "Step:71600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8625.76622891 clock:13858.83195000000160\n",
      "Step:71700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8637.75361705 clock:13878.16308500000014\n",
      "Step:71800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8649.76169300 clock:13897.47402700000021\n",
      "Step:71900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8661.80227709 clock:13916.82269000000088\n",
      "Step:72000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8673.78396511 clock:13936.13340000000062\n",
      "Step:72100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8685.81984401 clock:13955.46927500000129\n",
      "Step:72200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8697.80101609 clock:13974.78073200000108\n",
      "Step:72300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8709.79215288 clock:13994.08616500000062\n",
      "Step:72400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8721.78797293 clock:14013.41062700000111\n",
      "Step:72500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8733.77270389 clock:14032.74119600000085\n",
      "Step:72600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8745.75254893 clock:14052.06328399999984\n",
      "Step:72700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8757.75308299 clock:14071.37193200000002\n",
      "Step:72800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8769.77590704 clock:14090.70122900000024\n",
      "Step:72900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8781.77351308 clock:14110.01706000000013\n",
      "Step:73000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8793.87427497 clock:14129.37182900000153\n",
      "Step:73100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8806.01460099 clock:14148.71387599999980\n",
      "Step:73200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8818.04932308 clock:14168.01647400000002\n",
      "Step:73300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8830.03174305 clock:14187.31788100000085\n",
      "Step:73400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8841.99852800 clock:14206.63518600000134\n",
      "Step:73500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8853.97421002 clock:14225.93039600000156\n",
      "Step:73600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8865.96990609 clock:14245.27583200000117\n",
      "Step:73700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8877.94217801 clock:14264.59161900000072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:73800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8889.91943097 clock:14283.89599100000123\n",
      "Step:73900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8901.90843892 clock:14303.22278200000073\n",
      "Step:74000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8913.89347911 clock:14322.55142300000080\n",
      "Step:74100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8925.87530589 clock:14341.88943100000142\n",
      "Step:74200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8937.85564303 clock:14361.19223000000056\n",
      "Step:74300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8949.83729410 clock:14380.50150300000132\n",
      "Step:74400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8961.81446409 clock:14399.81213100000059\n",
      "Step:74500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8973.77273202 clock:14419.12934300000052\n",
      "Step:74600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:8985.78789592 clock:14438.48009900000034\n",
      "Step:74700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:8997.85324287 clock:14457.81648200000018\n",
      "Step:74800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9010.80220008 clock:14477.56777700000021\n",
      "Step:74900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9022.94195795 clock:14496.93690900000001\n",
      "Step:75000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9035.09191608 clock:14516.31849099999999\n",
      "Step:75100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9047.78176093 clock:14536.02597200000127\n",
      "Step:75200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9060.32909393 clock:14555.55224200000157\n",
      "Step:75300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9072.30982089 clock:14574.87102100000084\n",
      "Step:75400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9084.30093193 clock:14594.18218300000080\n",
      "Step:75500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9096.28879309 clock:14613.46838300000127\n",
      "Step:75600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9108.26449704 clock:14632.77129800000148\n",
      "Step:75700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9120.24834490 clock:14652.09605800000099\n",
      "Step:75800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9132.23863101 clock:14671.39731200000097\n",
      "Step:75900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9144.22844601 clock:14690.69936800000141\n",
      "Step:76000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9156.22884607 clock:14710.00987400000122\n",
      "Step:76100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9168.22501302 clock:14729.31115300000056\n",
      "Step:76200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9180.20068097 clock:14748.61206900000070\n",
      "Step:76300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9192.18177009 clock:14767.92949800000133\n",
      "Step:76400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9204.19299102 clock:14787.23564299999998\n",
      "Step:76500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9216.18569803 clock:14806.56554200000028\n",
      "Step:76600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9228.17874694 clock:14825.85300000000097\n",
      "Step:76700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9240.17132998 clock:14845.15380000000005\n",
      "Step:76800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9252.14956093 clock:14864.48224400000072\n",
      "Step:76900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9264.14671397 clock:14883.80185300000085\n",
      "Step:77000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9276.14499402 clock:14903.12589000000116\n",
      "Step:77100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9288.15685892 clock:14922.45230799999990\n",
      "Step:77200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9300.16353297 clock:14941.75765400000091\n",
      "Step:77300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9312.15761399 clock:14961.06297400000039\n",
      "Step:77400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9324.14663100 clock:14980.36484300000120\n",
      "Step:77500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9336.12356305 clock:14999.67494799999986\n",
      "Step:77600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9348.12401295 clock:15019.02056799999991\n",
      "Step:77700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9360.09882307 clock:15038.30297400000018\n",
      "Step:77800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9372.08064890 clock:15057.60324000000037\n",
      "Step:77900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9384.07922196 clock:15076.90282300000035\n",
      "Step:78000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9396.07452798 clock:15096.20332700000108\n",
      "Step:78100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9408.04504395 clock:15115.52048300000024\n",
      "Step:78200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9420.03773904 clock:15134.81978500000150\n",
      "Step:78300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9431.99110198 clock:15154.10509100000127\n",
      "Step:78400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9443.98120594 clock:15173.40417900000102\n",
      "Step:78500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9455.97943401 clock:15192.69786600000043\n",
      "Step:78600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9468.00108910 clock:15212.02611200000138\n",
      "Step:78700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9480.11461306 clock:15231.41334600000118\n",
      "Step:78800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9492.09123111 clock:15250.68845599999986\n",
      "Step:78900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9504.11621189 clock:15270.01717800000006\n",
      "Step:79000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9516.09476209 clock:15289.31144500000119\n",
      "Step:79100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9528.08669806 clock:15308.64775000000009\n",
      "Step:79200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9540.07346010 clock:15327.99735599999985\n",
      "Step:79300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9552.05905390 clock:15347.30782600000020\n",
      "Step:79400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9564.04272795 clock:15366.62014700000145\n",
      "Step:79500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9576.03033996 clock:15385.92343400000027\n",
      "Step:79600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9588.04988694 clock:15405.24092300000120\n",
      "Step:79700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9600.08548808 clock:15424.56902400000035\n",
      "Step:79800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9612.15737510 clock:15443.91263400000025\n",
      "Step:79900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9624.32217503 clock:15463.30207200000041\n",
      "Step:80000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9636.31446505 clock:15482.60086600000068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:80100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9648.31914306 clock:15501.91676000000007\n",
      "Step:80200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9660.30734301 clock:15521.20204800000101\n",
      "Step:80300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9672.32804108 clock:15540.49512000000141\n",
      "Step:80400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9684.34365988 clock:15559.79163599999993\n",
      "Step:80500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9696.32324910 clock:15579.08213600000090\n",
      "Step:80600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9708.32215500 clock:15598.39121400000113\n",
      "Step:80700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9720.31680608 clock:15617.72052200000144\n",
      "Step:80800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9732.33804488 clock:15637.04757400000017\n",
      "Step:80900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9744.38877797 clock:15656.36905200000001\n",
      "Step:81000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9756.04041195 clock:15675.41761500000030\n",
      "Step:81100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9767.70599103 clock:15694.50774900000033\n",
      "Step:81200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9779.36931109 clock:15713.57422899999983\n",
      "Step:81300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9791.05350399 clock:15732.63336600000002\n",
      "Step:81400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9802.74175191 clock:15751.71093100000144\n",
      "Step:81500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9814.40325689 clock:15770.74409900000137\n",
      "Step:81600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9826.07123995 clock:15789.80000699999982\n",
      "Step:81700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9837.72259498 clock:15808.84077900000011\n",
      "Step:81800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9849.40919304 clock:15827.88605900000039\n",
      "Step:81900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9861.07058811 clock:15846.94220000000132\n",
      "Step:82000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9872.71867490 clock:15866.00460300000123\n",
      "Step:82100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9884.39346409 clock:15885.04772300000150\n",
      "Step:82200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9896.06193089 clock:15904.08423300000140\n",
      "Step:82300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9907.73232794 clock:15923.13345900000058\n",
      "Step:82400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9919.38115692 clock:15942.20274299999983\n",
      "Step:82500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9931.05898309 clock:15961.24869500000023\n",
      "Step:82600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9942.73690009 clock:15980.30272400000104\n",
      "Step:82700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:9954.40934396 clock:15999.37828000000081\n",
      "Step:82800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9966.07373905 clock:16018.43979399999989\n",
      "Step:82900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9977.76162910 clock:16037.47180300000036\n",
      "Step:83000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:9989.42098498 clock:16056.51682400000027\n",
      "Step:83100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10001.10182309 clock:16075.60219599999982\n",
      "Step:83200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10012.76574802 clock:16094.65645899999981\n",
      "Step:83300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10024.45129609 clock:16113.72351400000116\n",
      "Step:83400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10036.13608599 clock:16132.78627600000073\n",
      "Step:83500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10047.82261610 clock:16151.89154600000074\n",
      "Step:83600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10059.49516296 clock:16170.91706300000078\n",
      "Step:83700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10071.15794706 clock:16190.00070100000084\n",
      "Step:83800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10082.83123589 clock:16209.06539900000098\n",
      "Step:83900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10094.52141094 clock:16228.07963200000086\n",
      "Step:84000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10106.20076609 clock:16247.13474800000040\n",
      "Step:84100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10117.89566088 clock:16266.20524600000135\n",
      "Step:84200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10129.56279802 clock:16285.25132400000075\n",
      "Step:84300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10141.25017905 clock:16304.29778500000066\n",
      "Step:84400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10152.90124702 clock:16323.35713300000134\n",
      "Step:84500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10164.57554007 clock:16342.38925800000106\n",
      "Step:84600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10176.24180007 clock:16361.48265600000013\n",
      "Step:84700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10187.92608595 clock:16380.55089899999984\n",
      "Step:84800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10199.60942698 clock:16399.60460099999909\n",
      "Step:84900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10211.28505301 clock:16418.66732100000081\n",
      "Step:85000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10222.98188710 clock:16437.72236200000043\n",
      "Step:85100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10234.67073107 clock:16456.76983100000143\n",
      "Step:85200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10246.33434606 clock:16475.84728900000118\n",
      "Step:85300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10258.01941109 clock:16494.92051999999967\n",
      "Step:85400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10269.70288897 clock:16513.98049100000208\n",
      "Step:85500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10281.36885691 clock:16533.03818200000023\n",
      "Step:85600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10293.05484390 clock:16552.07832699999926\n",
      "Step:85700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10304.73174405 clock:16571.11801600000035\n",
      "Step:85800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10316.42067003 clock:16590.16644100000121\n",
      "Step:85900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10328.09613800 clock:16609.22078700000202\n",
      "Step:86000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10339.75821090 clock:16628.25022800000079\n",
      "Step:86100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10351.45063996 clock:16647.30227400000149\n",
      "Step:86200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10363.13052392 clock:16666.38817900000140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:86300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10374.79460096 clock:16685.41448200000013\n",
      "Step:86400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10386.46332407 clock:16704.48164600000018\n",
      "Step:86500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10398.12839508 clock:16723.54738500000167\n",
      "Step:86600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10409.79289007 clock:16742.59773000000132\n",
      "Step:86700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10421.48450494 clock:16761.68067800000063\n",
      "Step:86800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10433.16478992 clock:16780.77751899999930\n",
      "Step:86900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10444.82139993 clock:16799.81424100000004\n",
      "Step:87000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10456.47004104 clock:16818.88195400000041\n",
      "Step:87100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10468.13321710 clock:16837.92024800000218\n",
      "Step:87200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10479.79423499 clock:16856.97846199999913\n",
      "Step:87300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10491.50026989 clock:16876.06641600000148\n",
      "Step:87400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10503.16366005 clock:16895.12525800000003\n",
      "Step:87500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10514.83368301 clock:16914.18454100000235\n",
      "Step:87600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10526.51630497 clock:16933.24500900000203\n",
      "Step:87700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10538.18737102 clock:16952.29016699999920\n",
      "Step:87800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10549.84784389 clock:16971.34394400000019\n",
      "Step:87900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10561.50255489 clock:16990.39986900000076\n",
      "Step:88000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10573.18466806 clock:17009.42320699999982\n",
      "Step:88100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10584.88220406 clock:17028.48454599999968\n",
      "Step:88200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10596.55412006 clock:17047.56119699999908\n",
      "Step:88300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10608.23768592 clock:17066.63072400000237\n",
      "Step:88400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10619.89804292 clock:17085.72184100000231\n",
      "Step:88500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10631.56413388 clock:17104.77635700000246\n",
      "Step:88600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10643.22887993 clock:17123.83960600000137\n",
      "Step:88700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10654.91380811 clock:17142.91407500000059\n",
      "Step:88800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10666.57181191 clock:17161.98403800000233\n",
      "Step:88900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10678.26670003 clock:17181.07131200000003\n",
      "Step:89000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10689.94801402 clock:17200.14266300000236\n",
      "Step:89100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10701.60140204 clock:17219.17153899999903\n",
      "Step:89200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10713.29708910 clock:17238.22802600000068\n",
      "Step:89300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10725.01829696 clock:17257.29715900000156\n",
      "Step:89400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10736.65252304 clock:17276.38128200000210\n",
      "Step:89500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10748.32930708 clock:17295.42561900000146\n",
      "Step:89600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10760.05376601 clock:17314.47191100000055\n",
      "Step:89700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10771.72919106 clock:17333.52545400000236\n",
      "Step:89800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10783.54869103 clock:17352.65888500000074\n",
      "Step:89900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10795.22419095 clock:17371.71601300000111\n",
      "Step:90000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10806.89552808 clock:17390.77995600000213\n",
      "Step:90100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10818.61728907 clock:17409.84476799999902\n",
      "Step:90200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10830.34979391 clock:17428.95130699999936\n",
      "Step:90300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10842.03333998 clock:17448.03311500000200\n",
      "Step:90400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10853.68009305 clock:17467.09061999999903\n",
      "Step:90500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10865.36387992 clock:17486.15223300000071\n",
      "Step:90600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10877.02468610 clock:17505.21141700000226\n",
      "Step:90700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10888.69117308 clock:17524.26286800000162\n",
      "Step:90800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10900.36490989 clock:17543.31981100000121\n",
      "Step:90900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10912.05500007 clock:17562.37236399999892\n",
      "Step:91000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10923.73978209 clock:17581.43100400000185\n",
      "Step:91100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10935.41621208 clock:17600.47110700000121\n",
      "Step:91200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10947.07000804 clock:17619.53451700000005\n",
      "Step:91300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10958.73689699 clock:17638.56103599999915\n",
      "Step:91400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10970.42079902 clock:17657.65532900000107\n",
      "Step:91500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:10982.19878292 clock:17676.74826699999903\n",
      "Step:91600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:10993.88187599 clock:17695.81646800000090\n",
      "Step:91700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11005.55343890 clock:17714.87001600000076\n",
      "Step:91800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11017.22313499 clock:17733.92757200000051\n",
      "Step:91900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11028.90254998 clock:17752.99758400000064\n",
      "Step:92000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11040.57104397 clock:17772.04923300000155\n",
      "Step:92100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11052.59187603 clock:17791.32437299999947\n",
      "Step:92200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11064.28378105 clock:17810.38541500000065\n",
      "Step:92300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11076.05009508 clock:17829.52013300000181\n",
      "Step:92400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11087.73842502 clock:17848.62678199999937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:92500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11099.40911102 clock:17867.69916300000114\n",
      "Step:92600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11111.07794309 clock:17886.74374800000078\n",
      "Step:92700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11122.76870108 clock:17905.82169799999974\n",
      "Step:92800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11134.44560790 clock:17924.88779300000169\n",
      "Step:92900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11146.12955189 clock:17943.97398900000189\n",
      "Step:93000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11158.23397398 clock:17963.04223700000148\n",
      "Step:93100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11169.91288495 clock:17982.11375500000213\n",
      "Step:93200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11181.72733903 clock:18001.18387900000016\n",
      "Step:93300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11193.92467403 clock:18020.30518099999972\n",
      "Step:93400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11205.70097399 clock:18039.40509200000088\n",
      "Step:93500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11218.12396693 clock:18058.64209200000187\n",
      "Step:93600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11229.96739888 clock:18077.77666500000123\n",
      "Step:93700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11242.03860188 clock:18096.70921000000089\n",
      "Step:93800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11253.86801100 clock:18115.66218800000206\n",
      "Step:93900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11266.36953688 clock:18134.95419500000207\n",
      "Step:94000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11279.78076696 clock:18154.41110599999956\n",
      "Step:94100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11292.51698589 clock:18173.74821900000097\n",
      "Step:94200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11304.82351398 clock:18193.12522600000011\n",
      "Step:94300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11316.90043306 clock:18212.45860200000243\n",
      "Step:94400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11328.95449090 clock:18231.82315000000017\n",
      "Step:94500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11340.98726511 clock:18251.18747799999983\n",
      "Step:94600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11353.02610207 clock:18270.54402300000220\n",
      "Step:94700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11365.04261398 clock:18289.89239699999962\n",
      "Step:94800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11377.07710505 clock:18309.24175000000105\n",
      "Step:94900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11389.11943507 clock:18328.60628400000132\n",
      "Step:95000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11401.16127491 clock:18347.97957500000120\n",
      "Step:95100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11413.17973804 clock:18367.35843899999963\n",
      "Step:95200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11425.36454606 clock:18386.74885999999969\n",
      "Step:95300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11437.55881596 clock:18406.14465399999972\n",
      "Step:95400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11449.77931190 clock:18425.53381599999921\n",
      "Step:95500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11462.24466395 clock:18445.03671000000031\n",
      "Step:95600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11475.13373089 clock:18464.36553700000150\n",
      "Step:95700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11487.16571903 clock:18483.73784399999931\n",
      "Step:95800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11499.18567896 clock:18503.09456900000077\n",
      "Step:95900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11511.19885397 clock:18522.43222700000115\n",
      "Step:96000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11523.22836900 clock:18541.77325900000142\n",
      "Step:96100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11535.26231694 clock:18561.12447400000019\n",
      "Step:96200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11547.26696205 clock:18580.47112399999969\n",
      "Step:96300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11559.27772188 clock:18599.81394300000102\n",
      "Step:96400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11571.42926502 clock:18619.19178300000203\n",
      "Step:96500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11583.73549008 clock:18638.70843900000182\n",
      "Step:96600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11595.75629210 clock:18658.05455000000075\n",
      "Step:96700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11607.91297889 clock:18677.41791799999919\n",
      "Step:96800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11619.94444895 clock:18696.79865799999970\n",
      "Step:96900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11632.04398894 clock:18716.16100300000107\n",
      "Step:97000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11644.07259202 clock:18735.52481600000101\n",
      "Step:97100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11656.08166289 clock:18754.86326700000063\n",
      "Step:97200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11668.09956288 clock:18774.22245300000213\n",
      "Step:97300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11680.12697411 clock:18793.58627500000148\n",
      "Step:97400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11692.15531898 clock:18812.96721299999990\n",
      "Step:97500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11704.30463505 clock:18832.33688700000130\n",
      "Step:97600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11716.76459193 clock:18851.76317399999971\n",
      "Step:97700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11728.78244805 clock:18871.11506300000110\n",
      "Step:97800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11741.29130411 clock:18890.57323499999984\n",
      "Step:97900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11753.69947791 clock:18910.13526500000080\n",
      "Step:98000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11765.73075008 clock:18929.51116000000184\n",
      "Step:98100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11778.06880307 clock:18948.92264699999942\n",
      "Step:98200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11790.18465805 clock:18968.30284500000198\n",
      "Step:98300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11802.50077009 clock:18987.70360699999947\n",
      "Step:98400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11815.06528497 clock:19007.08062699999937\n",
      "Step:98500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11827.09980607 clock:19026.44010999999955\n",
      "Step:98600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11839.13068700 clock:19045.82313900000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:98700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11851.59769511 clock:19065.14990200000102\n",
      "Step:98800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11863.69640899 clock:19084.51320200000191\n",
      "Step:98900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11875.72322989 clock:19103.85851800000091\n",
      "Step:99000 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11887.82749391 clock:19123.21478700000080\n",
      "Step:99100 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11899.86947107 clock:19142.58920600000056\n",
      "Step:99200 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11912.24055004 clock:19161.98696600000039\n",
      "Step:99300 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11924.33620501 clock:19181.38616499999989\n",
      "Step:99400 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11936.41307402 clock:19200.75617699999930\n",
      "Step:99500 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11948.48051691 clock:19220.11442800000077\n",
      "Step:99600 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209312 loss:0.00000000 time:11960.51482797 clock:19239.49906700000065\n",
      "Step:99700 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11972.55615401 clock:19258.84711199999947\n",
      "Step:99800 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11984.59869695 clock:19278.24860199999966\n",
      "Step:99900 batch_step:32 accuracy:1.00000000 full_accuracy:0.95209318 loss:0.00000000 time:11996.68981290 clock:19297.63105100000030\n",
      "finished enqueueing\n",
      "('Accuracy:', 1.0)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# MultiPerceptron\n",
    "# queueを使った学習\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "MODEL_DIR = \"../model_car_lidar_queue\"\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "data_cols = 3 # センサーの数。left45,front,right45\n",
    "n_classes = 4 # 予測結果の数。stop,left,forward,right\n",
    "batch_size = 100 # バッチサイズは10〜100前後に\n",
    "chunk_size = 100 # FIFOQueueのcapacity\n",
    "\n",
    "max_step = 100000 # ステップ数\n",
    "\n",
    "TRAIN_START_INDEX=0\n",
    "TRAIN_END_INDEX=batch_size\n",
    "TRAIN_INDEX_I=0\n",
    "# 学習データを読み込み pandasで読み込みnumpy.ndarrayに変換する\n",
    "csv_file=\"../TrainData/car_sensor_train_data.csv\"\n",
    "train_dataset = pd.io.parsers.read_csv(csv_file, header = 0, float_precision = \"high\").values\n",
    "TRAIN_NUM = len(train_dataset) # 学習データの行数\n",
    "\n",
    "def next_train_data(batch_size):\n",
    "    global TRAIN_START_INDEX\n",
    "    global TRAIN_END_INDEX\n",
    "    global TRAIN_NUM\n",
    "    global TRAIN_INDEX_I\n",
    "    global train_dataset\n",
    "\n",
    "    TRAIN_START_INDEX=TRAIN_INDEX_I*batch_size\n",
    "    TRAIN_END_INDEX=TRAIN_START_INDEX + batch_size\n",
    "    if TRAIN_NUM < TRAIN_START_INDEX:\n",
    "        TRAIN_START_INDEX=0\n",
    "        TRAIN_END_INDEX=TRAIN_START_INDEX + batch_size\n",
    "        TRAIN_INDEX_I=0\n",
    "    if TRAIN_NUM < TRAIN_END_INDEX:\n",
    "        TRAIN_END_INDEX=TRAIN_NUM\n",
    "\n",
    "    TRAIN_INDEX_I+=1\n",
    "\n",
    "    if TRAIN_START_INDEX==0:\n",
    "        # 先頭に戻った時は学習データをシャッフルする\n",
    "        train_dataset = shuffle(train_dataset, random_state=42) # shuffle train data\n",
    "\n",
    "    batch_data = train_dataset[TRAIN_START_INDEX:TRAIN_END_INDEX,0:data_cols]\n",
    "    batch_target = train_dataset[TRAIN_START_INDEX:TRAIN_END_INDEX,data_cols:]\n",
    "    return batch_data, batch_target\n",
    "\n",
    "\n",
    "TEST_START_INDEX=0\n",
    "TEST_END_INDEX=batch_size\n",
    "TEST_INDEX_I=0\n",
    "# csv読み込み pandasで読み込みnumpy.ndarrayに変換する\n",
    "csv_file=\"../TrainData/car_sensor_test_data.csv\"\n",
    "test_dataset = pd.io.parsers.read_csv(csv_file, header = 0, float_precision = \"high\").values\n",
    "TEST_NUM = len(test_dataset) # テストデータの行数\n",
    "\n",
    "def next_test_data(batch_size):\n",
    "    global TEST_START_INDEX\n",
    "    global TEST_END_INDEX\n",
    "    global TEST_NUM\n",
    "    global TEST_INDEX_I\n",
    "    global test_dataset\n",
    "\n",
    "    TEST_START_INDEX=TEST_INDEX_I*batch_size\n",
    "    TEST_END_INDEX=TEST_START_INDEX + batch_size\n",
    "    if TEST_NUM < TEST_START_INDEX:\n",
    "        TEST_START_INDEX=0\n",
    "        TEST_END_INDEX=TEST_START_INDEX + batch_size\n",
    "        TEST_INDEX_I=0\n",
    "    if TEST_NUM < TEST_END_INDEX:\n",
    "        TEST_END_INDEX=TEST_NUM\n",
    "\n",
    "    TEST_INDEX_I+=1\n",
    "\n",
    "    # テストデータは精度検証用なのでシャッフルは不要\n",
    "    batch_data = test_dataset[TEST_START_INDEX:TEST_END_INDEX,0:data_cols]\n",
    "    batch_target = test_dataset[TEST_START_INDEX:TEST_END_INDEX,data_cols:]\n",
    "    return batch_data, batch_target\n",
    "\n",
    "\n",
    "def load_and_enqueue(sess):\n",
    "    while True:\n",
    "        try:\n",
    "            batch_data, batch_target = next_train_data(batch_size)\n",
    "            sess.run(enqueue_op, feed_dict={placeholder_input_data:batch_data, placeholder_input_target:batch_target})\n",
    "        except tf.errors.CancelledError as e:\n",
    "            break\n",
    "    print(\"finished enqueueing\")\n",
    "\n",
    "with tf.variable_scope(\"input\"):\n",
    "    placeholder_input_data = tf.placeholder('float', [None, data_cols], name='input_data') # for load_and_enqueue. use dequeue_data_op for prediction\n",
    "    placeholder_input_target = tf.placeholder('float', name='input_target') # for load_and_enqueue. use dequeue_target_op for prediction\n",
    "    placeholder_batch_size = tf.placeholder(tf.int32, name='batch_size') # need feed_dict in training sess.run(). don't need for prediction.\n",
    "\n",
    "with tf.variable_scope(\"queue\"):\n",
    "    queue = tf.FIFOQueue(\n",
    "        capacity=chunk_size, # enqueue size\n",
    "        dtypes=['float', 'float'],\n",
    "        shapes=[[data_cols], [n_classes]],\n",
    "        name='FIFOQueue'\n",
    "    )\n",
    "\n",
    "    # Enqueue and dequeue operations\n",
    "    enqueue_op = queue.enqueue_many([placeholder_input_data, placeholder_input_target], name='enqueue_op')\n",
    "    dequeue_data_op, dequeue_target_op = queue.dequeue_many(placeholder_batch_size, name='dequeue_op') # instead of data/target placeholder\n",
    "\n",
    "\n",
    "with tf.variable_scope('neural_network_model'):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([data_cols, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    l1 = tf.add(tf.matmul(dequeue_data_op,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    # 予測結果\n",
    "    prediction = tf.add(tf.matmul(l3,output_layer['weights']), output_layer['biases'], name='output_y')\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    losses = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=dequeue_target_op)\n",
    "    loss_op = tf.reduce_mean(losses, name='cost')\n",
    "    tf.summary.scalar('loss', loss_op)\n",
    "\n",
    "with tf.variable_scope('accuracy'):\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(dequeue_target_op, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'), name='accuracy')\n",
    "    accuracy = tf.Print(accuracy, data=[accuracy], message=\"accuracy:\")\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(0.0001).minimize(loss_op, name='train_op')\n",
    "num_batchs = int(TRAIN_NUM/batch_size)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "test_data, test_target =next_test_data(TEST_NUM)\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(MODEL_DIR)\n",
    "    if ckpt:\n",
    "        # checkpointファイルから最後に保存したモデルへのパスを取得する\n",
    "        last_model = ckpt.model_checkpoint_path\n",
    "        print((\"load {0}\".format(last_model)))\n",
    "        # 学習済みモデルを読み込む\n",
    "        saver.restore(sess, last_model)\n",
    "        LOAD_MODEL = True\n",
    "    else:\n",
    "        print(\"initialization\")\n",
    "        # 初期化処理\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "\n",
    "    writer = tf.summary.FileWriter('./log', sess.graph)        \n",
    "    start_time, start_clock = time.time(), time.clock()\n",
    "\n",
    "    # Start a thread to enqueue data asynchronously, and hide I/O latency.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_thread = threading.Thread(target=load_and_enqueue, args=[sess])\n",
    "    enqueue_thread.isDaemon()\n",
    "    enqueue_thread.start()\n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "    try:\n",
    "        # check the accuracy before training (without feed_dict!)\n",
    "        print(sess.run(accuracy, feed_dict={placeholder_batch_size:chunk_size})) # check batch_size's data\n",
    "        for step in range(max_step):\n",
    "            batch_loss=0\n",
    "            w_summary=None\n",
    "            for batch_step in range(num_batchs): # 分割したミニバッチを全て実行する\n",
    "                _, loss, w_summary = sess.run([train_op, loss_op, summary_op],\n",
    "                                   feed_dict={placeholder_batch_size:batch_size})\n",
    "                batch_loss += loss\n",
    "            if not w_summary is None:\n",
    "                writer.add_summary(w_summary, step)\n",
    "    \n",
    "            ac = sess.run(accuracy, feed_dict={placeholder_batch_size:chunk_size}) # check batch_size's data\n",
    "\n",
    "            # 全テストデータでの精度を確認する\n",
    "            full_test_accuracy = accuracy.eval({'queue/dequeue_op:0':test_data,\n",
    "                                                'queue/dequeue_op:1':test_target})\n",
    "            if step % 100 == 0:\n",
    "                print(\"Step:%d batch_step:%d accuracy:%.8f full_accuracy:%.8f loss:%.8f time:%.8f clock:%.14f\" % (step,batch_step,ac,full_test_accuracy,batch_loss,time.time()-start_time,time.clock()-start_clock))\n",
    "\n",
    "        sess.run(queue.close(cancel_pending_enqueues=True))\n",
    "    except Exception, e:\n",
    "        # Report exceptions to the coodinator.\n",
    "        print(e)\n",
    "        coord.request_stop(e)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "    saver.save(sess, MODEL_DIR + '/model.ckpt')\n",
    "\n",
    "\n",
    "    # 全学習データでの精度を確認する\n",
    "    test_data, test_target =next_train_data(TRAIN_NUM)\n",
    "    print('Accuracy:',accuracy.eval({dequeue_data_op:test_data,\n",
    "                                     dequeue_target_op:test_target}))\n",
    "\n",
    "\n",
    "\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
